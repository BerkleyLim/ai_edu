{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Deep Convolutional GAN 2\n",
    "- ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ê¸°"
   ],
   "id": "c8993c0a7678a202"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:03:04.088862Z",
     "start_time": "2025-07-26T06:03:04.079146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì‹¤í–‰ê²°ê³¼\n",
    "# - í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# - GAN í•™ìŠµì„ ìœ„í•œ ê¸°ë³¸ì ì¸ í™˜ê²½ êµ¬ì¶•\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "# from google.colab import drive # êµ¬ê¸€ ì½”ë©ì—ì„œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "from torchvision.datasets import ImageFolder # ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "# from google.colab import files # ì½”ë©ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "from IPython.display import display, HTML # ì£¼í”¼í„°/ì½”ë© í™˜ê²½ì—ì„œ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "# # êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì´ë‚˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥/ë¡œë“œí•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# try:\n",
    "#     drive.mount('/content/drive')\n",
    "#     print(\"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ì„±ê³µ!\")\n",
    "# except:\n",
    "#     print(\"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ì‹¤íŒ¨ ë˜ëŠ” ë§ˆìš´íŠ¸ ì·¨ì†Œ\")"
   ],
   "id": "5da52ad10346352d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:03:28.770555Z",
     "start_time": "2025-07-26T06:03:28.752273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì‹¤í–‰ ê²°ê³¼\n",
    "# - ì¬í˜„ì„± í™•ë³´ ë° ì¥ì¹˜ ì„¤ì •ì„ ìœ„í•œ ì´ˆê¸° ì„¤ì •\n",
    "# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): # CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ìš° GPU ì‹œë“œë„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True # ê²°ì •ë¡ ì  CUDA ì—°ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì‹œë“œë¥¼ 42ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "set_seed(42)\n",
    "\n",
    "# í•™ìŠµì— ì‚¬ìš©í•  ì¥ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")"
   ],
   "id": "b956a1a5691d492c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¥ì¹˜: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:03:54.577422Z",
     "start_time": "2025-07-26T06:03:54.559960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# í•™ìŠµì— ì‚¬ìš©ë  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ëª¨ë¸ ì„¤ì •ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "batch_size = 64 # í•œ ë²ˆì˜ í•™ìŠµ iterationì— ì‚¬ìš©í•  ì´ë¯¸ì§€ ìˆ˜\n",
    "image_size = 64 # ì´ë¯¸ì§€ í¬ê¸° (64x64 í”½ì…€)\n",
    "nz = 100 # ìƒì„±ìì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  ë…¸ì´ì¦ˆ ë²¡í„°ì˜ í¬ê¸°\n",
    "ngf = 64 # ìƒì„±ìì˜ ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ê³„ì¸µì˜ í•„í„° ìˆ˜ (ì±„ë„ ìˆ˜)\n",
    "ndf = 64 # íŒë³„ìì˜ ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ê³„ì¸µì˜ í•„í„° ìˆ˜ (ì±„ë„ ìˆ˜)\n",
    "num_epochs = 50 # ì „ì²´ ë°ì´í„°ì…‹ì„ ë°˜ë³µí•  íšŸìˆ˜\n",
    "lr = 0.0003 # í•™ìŠµë¥  (learning rate)\n",
    "beta1 = 0.5 # Adam optimizerì˜ ë² íƒ€1 íŒŒë¼ë¯¸í„°"
   ],
   "id": "690672dcb49f52f1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:04:13.918018Z",
     "start_time": "2025-07-26T06:04:13.914336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CIFAR-10 ë°ì´í„°ì…‹ì—ì„œ ê°•ì•„ì§€ ì´ë¯¸ì§€ë§Œ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def download_dog_dataset():\n",
    "    print(\"ê°•ì•„ì§€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "    import torchvision.datasets as datasets # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ torchvision.datasetsì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "    # CIFAR-10 ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. train=TrueëŠ” í•™ìŠµ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "    cifar10 = datasets.CIFAR10(root='./cifar10', download=True, train=True)\n",
    "\n",
    "    # CIFAR-10 í´ë˜ìŠ¤ ëª©ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    class_labels = cifar10.classes\n",
    "    print(f\"CIFAR-10 í´ë˜ìŠ¤ ëª©ë¡: {class_labels}\")\n",
    "\n",
    "    # 'dog' í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    dog_idx = class_labels.index('dog')\n",
    "    print(f\"ê°•ì•„ì§€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {dog_idx}\")\n",
    "\n",
    "    # CIFAR-10 ë°ì´í„°ì…‹ì—ì„œ ê°•ì•„ì§€ ì´ë¯¸ì§€ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    dog_images = []\n",
    "\n",
    "    for i in range(len(cifar10)):\n",
    "        img, label = cifar10[i]\n",
    "        if label == dog_idx: # ë¼ë²¨ì´ ê°•ì•„ì§€ ì¸ë±ìŠ¤ì™€ ê°™ìœ¼ë©´ ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "            dog_images.append(img)\n",
    "\n",
    "    print(f\"{len(dog_images)}ê°œì˜ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ì¶”ì¶œí•œ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    os.makedirs('./dog_dataset/dogs', exist_ok=True)\n",
    "\n",
    "    # ì¶”ì¶œëœ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ì§€ì •ëœ í´ë”ì— JPEG í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    for i, img in enumerate(dog_images):\n",
    "        img.save(f'./dog_dataset/dogs/dog_{i}.jpg')\n",
    "\n",
    "    print(f\"ì´ë¯¸ì§€ë¥¼ './dog_dataset/dogs/' í´ë”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    return './dog_dataset' # ì €ì¥ëœ ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ],
   "id": "765cdf001d24ea0e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:07:26.038076Z",
     "start_time": "2025-07-26T06:07:25.986792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ë°ì´í„°ì…‹ì„ í™•ì¸í•˜ê³  í•„ìš”í•œ ê²½ìš° ë‹¤ìš´ë¡œë“œí•œ í›„ ë°ì´í„° ë¡œë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    # './dog_dataset' í´ë”ê°€ ì¡´ì¬í•˜ê³  ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    if not os.path.exists('./dog_dataset') or len(glob.glob('./dog_dataset/*/*.jpg')) == 0:\n",
    "        data_root = download_dog_dataset() # ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    else:\n",
    "        data_root = './dog_dataset' # ë°ì´í„°ì…‹ì´ ìˆìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        print(f\"ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš©: {data_root}\")\n",
    "except:\n",
    "    # ë°ì´í„°ì…‹ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.\n",
    "    print(\"ë°ì´í„°ì…‹ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "    data_root = download_dog_dataset()\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³€í™˜(Transform)ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "# - Resize: ì´ë¯¸ì§€ í¬ê¸°ë¥¼ image_size x image_sizeë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
    "# - CenterCrop: ì¤‘ì•™ ë¶€ë¶„ì„ image_size x image_sizeë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
    "# - ToTensor: PIL ì´ë¯¸ì§€ë¥¼ PyTorch Tensorë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "# - Normalize: ì´ë¯¸ì§€ í”½ì…€ ê°’ì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# ImageFolderë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤. ImageFolderëŠ” í´ë” êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    dataset = ImageFolder(root=data_root, transform=transform)\n",
    "    # ë°ì´í„° ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. í•™ìŠµ ì‹œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    print(f\"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)} ì´ë¯¸ì§€\")\n",
    "except Exception as e:\n",
    "    # ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì„ì˜ì˜ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    print(f\"ë°ì´í„°ì…‹ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ì„ì˜ ë°ì´í„°ë¡œ ì½”ë“œë¥¼ ê³„ì† ì‹¤í–‰í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    # ì„ì˜ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "    def create_random_dataset(num_samples=1000):\n",
    "        random_data = torch.randn(num_samples, 3, image_size, image_size) # ëœë¤ ë…¸ì´ì¦ˆë¡œ ì´ë¯¸ì§€ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        random_data = torch.clamp((random_data * 0.2) + 0.5, 0, 1)  # ê°’ ë²”ìœ„ë¥¼ [0, 1]ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "        random_dataset = [(img, 0) for img in random_data]  # (ì´ë¯¸ì§€, ë¼ë²¨) í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤. (ë¼ë²¨ì€ ì„ì˜ë¡œ 0ìœ¼ë¡œ ì„¤ì •)\n",
    "        return random_dataset\n",
    "\n",
    "    # ì‚¬ìš©ì ì •ì˜ RandomDataset í´ë˜ìŠ¤ì…ë‹ˆë‹¤. DataLoaderì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ PyTorch Datasetì„ ìƒì†í•©ë‹ˆë‹¤.\n",
    "    class RandomDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx] # ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    random_dataset = RandomDataset(create_random_dataset()) # ì„ì˜ ë°ì´í„°ì…‹ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    # ì„ì˜ ë°ì´í„°ì…‹ì„ ìœ„í•œ ë°ì´í„° ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    dataloader = DataLoader(random_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"ì„ì˜ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {len(random_dataset)} ì´ë¯¸ì§€\")"
   ],
   "id": "3cdda284d34fcc33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš©: ./dog_dataset\n",
      "ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: 5000 ì´ë¯¸ì§€\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:07:40.771486Z",
     "start_time": "2025-07-26T06:07:40.670840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. DCGAN ë…¼ë¬¸ì˜ ê¶Œì¥ ì‚¬í•­ì„ ë”°ë¦…ë‹ˆë‹¤.\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # Conv ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ í‰ê·  0.0, í‘œì¤€í¸ì°¨ 0.02ì¸ ì •ê·œë¶„í¬ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    # BatchNorm ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ í‰ê·  1.0, í‘œì¤€í¸ì°¨ 0.02ì¸ ì •ê·œë¶„í¬ë¡œ ì´ˆê¸°í™”í•˜ê³ , biasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# ìƒì„±ì (Generator) ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Sequential ëª¨ë¸ì€ ê³„ì¸µë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "        self.main = nn.Sequential(\n",
    "            # ConvTranspose2d (Deconvolution) ê³„ì¸µì„ ì‚¬ìš©í•˜ì—¬ ë…¸ì´ì¦ˆ ë²¡í„°ì—ì„œ ì´ë¯¸ì§€ë¡œ í¬ê¸°ë¥¼ í‚¤ì›ë‹ˆë‹¤.\n",
    "            # nz: ì…ë ¥ ì±„ë„ ìˆ˜ (ë…¸ì´ì¦ˆ ë²¡í„° í¬ê¸°)\n",
    "            # ngf * 8: ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "            # 4: ì»¤ë„ í¬ê¸°\n",
    "            # 1: ìŠ¤íŠ¸ë¼ì´ë“œ\n",
    "            # 0: íŒ¨ë”©\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8), # ë°°ì¹˜ ì •ê·œí™” ê³„ì¸µ\n",
    "            nn.ReLU(True), # ReLU í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # ë§ˆì§€ë§‰ ê³„ì¸µ: 3ì±„ë„ (RGB) ì´ë¯¸ì§€ ì¶œë ¥ì„ ìœ„í•´ ìŠ¤íŠ¸ë¼ì´ë“œ 2ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh() # Tanh í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ í”½ì…€ ê°’ì„ [-1, 1] ë²”ìœ„ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "        )\n",
    "\n",
    "    # forward ë©”ì„œë“œëŠ” ì…ë ¥ í…ì„œë¥¼ ë°›ì•„ ëª¨ë¸ì„ í†µê³¼ì‹œí‚¨ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# íŒë³„ì (Discriminator) ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Conv2d ê³„ì¸µì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  í¬ê¸°ë¥¼ ì¤„ì…ë‹ˆë‹¤.\n",
    "            # 3: ì…ë ¥ ì±„ë„ ìˆ˜ (RGB ì´ë¯¸ì§€)\n",
    "            # ndf: ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "            # 4: ì»¤ë„ í¬ê¸°\n",
    "            # 2: ìŠ¤íŠ¸ë¼ì´ë“œ\n",
    "            # 1: íŒ¨ë”©\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # LeakyReLU í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # ë§ˆì§€ë§‰ ê³„ì¸µ: ì´ë¯¸ì§€ì˜ ì§„ì§œ/ê°€ì§œë¥¼ íŒë³„í•˜ê¸° ìœ„í•´ 1ê°œì˜ ì¶œë ¥ ì±„ë„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid() # Sigmoid í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶œë ¥ì„ [0, 1] ë²”ìœ„ì˜ í™•ë¥  ê°’ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "        )\n",
    "\n",
    "    # forward ë©”ì„œë“œëŠ” ì…ë ¥ í…ì„œë¥¼ ë°›ì•„ íŒë³„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    # .view(-1, 1).squeeze(1)ëŠ” ì¶œë ¥ì„ 1ì°¨ì› í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "# ìƒì„±ìì™€ íŒë³„ì ëª¨ë¸ ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ì§€ì •ëœ ì¥ì¹˜(GPU ë˜ëŠ” CPU)ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\"ìƒì„±ì ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(netG)\n",
    "print(\"\\níŒë³„ì ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(netD)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ë¡œ Binary Cross Entropy (BCELoss)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. GAN í•™ìŠµì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# í•™ìŠµ ê³¼ì • ì¤‘ ìƒì„± ì„±ëŠ¥ì„ í™•ì¸í•˜ê¸° ìœ„í•œ ê³ ì •ëœ ë…¸ì´ì¦ˆ ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# ì§„ì§œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# ìƒì„±ìì™€ íŒë³„ìë¥¼ ìœ„í•œ Adam optimizerë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ],
   "id": "686c3200925f7a70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ì ëª¨ë¸ êµ¬ì¡°:\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "\n",
      "íŒë³„ì ëª¨ë¸ êµ¬ì¡°:\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:07:53.821835Z",
     "start_time": "2025-07-26T06:07:53.818551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def visualize_images(images, title=None, display_in_notebook=True):\n",
    "    # ì´ë¯¸ì§€ë¥¼ [-1, 1] ë²”ìœ„ì—ì„œ [0, 1] ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    images = (images + 1) / 2.0\n",
    "\n",
    "    # ì´ë¯¸ì§€ ê·¸ë¦¬ë“œë¥¼ ë§Œë“­ë‹ˆë‹¤. ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì‹œê°í™”í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    grid = torchvision.utils.make_grid(images, padding=2, normalize=False)\n",
    "    # PyTorch í…ì„œë¥¼ Matplotlibì—ì„œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” numpy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì±„ë„ ìˆœì„œë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "    img = grid.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # ì´ë¯¸ì§€ë¥¼ í”Œë¡œíŒ…í•©ë‹ˆë‹¤.\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    # ì œëª©ì´ ìˆìœ¼ë©´ ì œëª©ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    # ì¶• ì •ë³´ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    plt.axis('off')\n",
    "\n",
    "    # ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "    if display_in_notebook:\n",
    "        plt.show()\n",
    "\n",
    "    return img # ì‹œê°í™”ëœ ì´ë¯¸ì§€ì˜ numpy ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë”ì™€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# í•™ìŠµ ì¤‘ ìƒì„±ìì™€ íŒë³„ìì˜ ì†ì‹¤ ê°’ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "# ê° ì—í­ì˜ ë§ˆì§€ë§‰ì— ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "img_list = []"
   ],
   "id": "f3ea46e84a09ca88",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-26T06:08:01.441911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” ê°„ë‹¨í•œ í”„ë¡œê·¸ë ˆìŠ¤ ë°” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def progress_bar(current, total, bar_length=50):\n",
    "    fraction = current / total # ì „ì²´ ì¤‘ í˜„ì¬ ì§„í–‰ëœ ë¹„ìœ¨\n",
    "    arrow = int(fraction * bar_length) * '=' # ì§„í–‰ëœ ë¶€ë¶„ì„ ë‚˜íƒ€ë‚´ëŠ” '=' ë¬¸ìì—´\n",
    "    padding = (bar_length - len(arrow)) * ' ' # ë‚¨ì€ ë¶€ë¶„ì„ ë‚˜íƒ€ë‚´ëŠ” ê³µë°± ë¬¸ìì—´\n",
    "    return f\"[{arrow}{padding}] {int(fraction * 100)}%\" # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë¬¸ìì—´ ë°˜í™˜\n",
    "\n",
    "# GAN í•™ìŠµ ë°˜ë³µë¬¸ì…ë‹ˆë‹¤. num_epochs ë§Œí¼ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time() # ê° ì—í­ì˜ ì‹œì‘ ì‹œê°„ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "    # ë°ì´í„° ë¡œë”ì—ì„œ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # íŒë³„ì ë„¤íŠ¸ì›Œí¬ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "        netD.zero_grad()\n",
    "        # ë¡œë“œëœ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        if isinstance(data, list) and len(data) == 2:\n",
    "            real_cpu = data[0].to(device) # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì´ë¯¸ì§€ ë°ì´í„°ë¼ê³  ê°€ì •í•˜ê³  ì¥ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "        else:\n",
    "            real_cpu = data[0].to(device) # ì´ë¯¸ì§€ê°€ ë°”ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œë¼ê³  ê°€ì •í•˜ê³  ì¥ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "\n",
    "        batch_size = real_cpu.size(0) # í˜„ì¬ ë°°ì¹˜ì˜ í¬ê¸°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ í…ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ë¥¼ íŒë³„ì ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ì‹œí‚µë‹ˆë‹¤.\n",
    "        output = netD(real_cpu)\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ íŒë³„ìì˜ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. íŒë³„ìëŠ” ì§„ì§œ ì´ë¯¸ì§€ë¥¼ 1ë¡œ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        errD_real = criterion(output, label)\n",
    "        # ì—­ì „íŒŒë¥¼ í†µí•´ íŒë³„ìì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item() # íŒë³„ìê°€ ì§„ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ ì˜ˆì¸¡í•œ í‰ê·  í™•ë¥ ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "        # ìƒì„±ì ë„¤íŠ¸ì›Œí¬ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ë…¸ì´ì¦ˆ ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        # ìƒì„±ì ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        fake = netG(noise)\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ í…ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        label.fill_(fake_label)\n",
    "\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ë¥¼ íŒë³„ì ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ì‹œí‚µë‹ˆë‹¤. .detach()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±ì ìª½ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ê°€ íë¥´ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n",
    "        output = netD(fake.detach())\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ íŒë³„ìì˜ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. íŒë³„ìëŠ” ê°€ì§œ ì´ë¯¸ì§€ë¥¼ 0ìœ¼ë¡œ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        errD_fake = criterion(output, label)\n",
    "        # ì—­ì „íŒŒë¥¼ í†µí•´ íŒë³„ìì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item() # íŒë³„ìê°€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ ì˜ˆì¸¡í•œ í‰ê·  í™•ë¥  (ìƒì„±ì í•™ìŠµ ì „ì— ê¸°ë¡)\n",
    "\n",
    "        # íŒë³„ìì˜ ì´ ì†ì‹¤ì€ ì§„ì§œ ì´ë¯¸ì§€ ì†ì‹¤ê³¼ ê°€ì§œ ì´ë¯¸ì§€ ì†ì‹¤ì˜ í•©ì…ë‹ˆë‹¤.\n",
    "        errD = errD_real + errD_fake\n",
    "        # íŒë³„ì ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "        optimizerD.step()\n",
    "\n",
    "        # ìƒì„±ì ë„¤íŠ¸ì›Œí¬ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "        netG.zero_grad()\n",
    "        # ìƒì„±ì í•™ìŠµì„ ìœ„í•´ ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ì„ 'ì§„ì§œ' (1)ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ìƒì„±ìëŠ” íŒë³„ìê°€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ ì°©ê°í•˜ê²Œ ë§Œë“¤ë ¤ê³  í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "        label.fill_(real_label)\n",
    "\n",
    "        # ìƒì„±ìê°€ ë§Œë“  ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ íŒë³„ì ë„¤íŠ¸ì›Œí¬ì— í†µê³¼ì‹œí‚µë‹ˆë‹¤.\n",
    "        output = netD(fake)\n",
    "        # ìƒì„±ìì˜ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ìƒì„±ìëŠ” íŒë³„ìê°€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ íŒë‹¨í•˜ë„ë¡ ìœ ë„í•˜ë¯€ë¡œ ë¼ë²¨ì„ 1ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        errG = criterion(output, label)\n",
    "        # ì—­ì „íŒŒë¥¼ í†µí•´ ìƒì„±ìì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item() # íŒë³„ìê°€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ ì˜ˆì¸¡í•œ í‰ê·  í™•ë¥  (ìƒì„±ì í•™ìŠµ í›„ì— ê¸°ë¡)\n",
    "\n",
    "        # ìƒì„±ì ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "        optimizerG.step()\n",
    "\n",
    "        # í•™ìŠµ ì¤‘ ì†ì‹¤ ê°’ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # 10 ë°°ì¹˜ë§ˆë‹¤ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "        if i % 10 == 0:\n",
    "            prog = progress_bar(i, len(dataloader)) # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë¬¸ìì—´ ìƒì„±\n",
    "            print(f'\\rì—í­ [{epoch+1}/{num_epochs}] ë°°ì¹˜ {prog} '\n",
    "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}', end='') # í˜„ì¬ ë¼ì¸ì— ì¶œë ¥í•˜ê³  ì¤„ë°”ê¿ˆí•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "    print(' ') # ì—í­ì˜ ëì—ì„œ ì¤„ë°”ê¿ˆí•©ë‹ˆë‹¤.\n",
    "\n",
    "    # ê° ì—í­ì˜ ëì—ì„œ ê³ ì •ëœ ë…¸ì´ì¦ˆë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ í•™ìŠµ ì§„í–‰ ìƒí™©ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    with torch.no_grad(): # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "        fake = netG(fixed_noise).detach().cpu() # ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  CPUë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n",
    "    img_list.append(fake) # ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "    # ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    img = visualize_images(fake, title=f'epoch {epoch+1} Result')\n",
    "\n",
    "    # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    plt.savefig(f'results/fake_dogs_epoch_{epoch+1}.png')\n",
    "    plt.close() # í˜„ì¬ í”Œë¡¯ì„ ë‹«ì•„ ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.\n",
    "\n",
    "    # 5 ì—í­ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì—í­ì—ì„œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n",
    "        torch.save({\n",
    "            'generator': netG.state_dict(), # ìƒì„±ì ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜\n",
    "            'discriminator': netD.state_dict(), # íŒë³„ì ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜\n",
    "            'optimizerG': optimizerG.state_dict(), # ìƒì„±ì ì˜µí‹°ë§ˆì´ì € ìƒíƒœ\n",
    "            'optimizerD': optimizerD.state_dict(), # íŒë³„ì ì˜µí‹°ë§ˆì´ì € ìƒíƒœ\n",
    "            'epoch': epoch, # í˜„ì¬ ì—í­ ë²ˆí˜¸\n",
    "            'G_losses': G_losses, # ìƒì„±ì ì†ì‹¤ ê¸°ë¡\n",
    "            'D_losses': D_losses, # íŒë³„ì ì†ì‹¤ ê¸°ë¡\n",
    "        }, f'checkpoints/gan_model_epoch_{epoch+1}.pth') # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n",
    "        print(f\"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: ì—í­ {epoch+1}\")\n",
    "\n",
    "    # ì—í­ë³„ ì†Œìš” ì‹œê°„ì„ ê³„ì‚°í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'ì—í­ {epoch+1} ì™„ë£Œ, ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ')\n",
    "\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")"
   ],
   "id": "e2d2fbb01f16628c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ì‹œì‘...\n",
      "ì—í­ [1/50] ë°°ì¹˜ [===============================                   ] 63% Loss_D: 2.3174 Loss_G: 14.1506 D(x): 0.9179 D(G(z)): 0.8612/0.0000"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ìƒì„±ìì™€ íŒë³„ìì˜ ì†ì‹¤ ê·¸ë˜í”„ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Loss of Generator and Discriminator\")\n",
    "plt.plot(G_losses, label=\"Generator\") # ìƒì„±ì ì†ì‹¤ í”Œë¡¯\n",
    "plt.plot(D_losses, label=\"Discriminator\") # íŒë³„ì ì†ì‹¤ í”Œë¡¯\n",
    "plt.xlabel(\"Repeat\") # xì¶• ë ˆì´ë¸”\n",
    "plt.ylabel(\"Loss\") # yì¶• ë ˆì´ë¸”\n",
    "plt.legend() # ë²”ë¡€ í‘œì‹œ\n",
    "plt.savefig('results/loss_plot.png') # ê·¸ë˜í”„ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "plt.show() # ê·¸ë˜í”„ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "plt.close() # í˜„ì¬ í”Œë¡¯ì„ ë‹«ìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ê° ì—í­ì˜ ë§ˆì§€ë§‰ì— ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ ê·¸ë¦¬ë“œë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "plt.figure(figsize=(12, 12))\n",
    "# ê·¸ë¦¬ë“œì˜ í–‰ê³¼ ì—´ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "rows = int(np.sqrt(num_epochs))\n",
    "cols = int(np.ceil(num_epochs / rows))\n",
    "\n",
    "# ê° ì—í­ë³„ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ ì¤‘ ì¼ë¶€(16ê°œ)ë¥¼ ì„œë¸Œí”Œë¡¯ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "for i in range(min(num_epochs, len(img_list))): # í•™ìŠµ ì—í­ ë˜ëŠ” ì €ì¥ëœ ì´ë¯¸ì§€ ìˆ˜ ì¤‘ ì‘ì€ ê°’ë§Œí¼ ë°˜ë³µ\n",
    "    plt.subplot(rows, cols, i + 1) # ì„œë¸Œí”Œë¡¯ ìœ„ì¹˜ ì„¤ì •\n",
    "    plt.axis('off') # ì¶• ìˆ¨ê¸°ê¸°\n",
    "    plt.title(f'epoch {i+1}') # ì„œë¸Œí”Œë¡¯ ì œëª© (ì—í­ ë²ˆí˜¸)\n",
    "\n",
    "    if i < len(img_list):\n",
    "        # ì €ì¥ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì—í­ì˜ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ ê·¸ë¦¬ë“œë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "        img = torchvision.utils.make_grid(img_list[i][:16], padding=2, normalize=True)\n",
    "        # ì´ë¯¸ì§€ë¥¼ Matplotlibì—ì„œ í‘œì‹œí•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "        plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n",
    "\n",
    "plt.tight_layout() # ì„œë¸Œí”Œë¡¯ ê°„ì˜ ê°„ê²©ì„ ìë™ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "plt.savefig('results/progress.png') # ì´ë¯¸ì§€ ê·¸ë¦¬ë“œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "plt.show() # ì´ë¯¸ì§€ ê·¸ë¦¬ë“œë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "# í•™ìŠµì´ ì™„ë£Œëœ ìƒì„±ì ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def generate_new_dogs(num_images=16):\n",
    "    netG.eval() # ìƒì„±ì ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤ (ë“œë¡­ì•„ì›ƒ ë“± ë¹„í™œì„±í™”).\n",
    "\n",
    "    with torch.no_grad(): # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "        # ìƒˆë¡œìš´ ë…¸ì´ì¦ˆ ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "        noise = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "\n",
    "        # ìƒì„±ì ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  CPUë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n",
    "        fake_dogs = netG(noise).detach().cpu()\n",
    "\n",
    "        # ìƒì„±ëœ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë“¤ì„ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.\n",
    "        visualize_images(fake_dogs, title=f'Generated Dog Image {num_images}')\n",
    "        plt.savefig('results/final_generated_dogs.png') # ìµœì¢… ìƒì„± ì´ë¯¸ì§€ ì €ì¥\n",
    "\n",
    "        print(f\"{num_images}ê°œì˜ ìƒˆë¡œìš´ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ('results/final_generated_dogs.png'ì— ì €ì¥)\")\n",
    "\n",
    "        return fake_dogs # ìƒì„±ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "print(\"\\nìµœì¢… ëª¨ë¸ë¡œ ìƒˆ ì´ë¯¸ì§€ ìƒì„±:\")\n",
    "generate_new_dogs(16) # ìµœì¢… ëª¨ë¸ë¡œ 16ê°œì˜ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë°©ë²•ì„ ì•ˆë‚´í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def download_results():\n",
    "    print(\"\\nìƒì„±ëœ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ:\")\n",
    "    print(\"1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ íƒ­(ğŸ“)ì„ í´ë¦­í•©ë‹ˆë‹¤.\")\n",
    "    print(\"2. 'results' í´ë”ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "    print(\"ë˜ëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "    print(\"files.download('results/final_generated_dogs.png')\")\n",
    "    print(\"files.download('results/progress.png')\")\n",
    "    print(\"files.download('results/loss_plot.png')\")\n",
    "\n",
    "print(\"\\n=== GAN ì‹¤ìŠµ2 ì™„ë£Œ ===\")\n",
    "print(\"ìƒì„±ëœ ëª¨ë“  ê²°ê³¼ëŠ” 'results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "download_results() # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
   ],
   "id": "cafc81753983ea43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
