{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3주차 - 250719",
   "id": "344e0b7dde47b730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNN\n",
    "## CNN(Convolution Neural Network) 역사\n",
    "- 1989년 LeCun이 발표한 논문 \"Backpropagation applied to handwritten zip code recognition\" 에서 처음 소개됨\n",
    "- 2003년 Behnke의 논문 \"Hierarchical Neural Networks for Image Interpretation\"을 통해 일반화\n",
    "- Simard 논문 \"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis\"에서 단순화\n",
    "\n",
    "## 기존 MLNN(Multi-Layer NN) 문제점\n",
    "- 변수 갯수\n",
    "- 네트워크 크기\n",
    "- 학습 시간\n",
    "\n",
    "## CNN 구조\n",
    "- 합성곱 계층(Convolutional Layer)과 풀링 계층(Pooling Layer) 추가\n",
    "\n",
    "### 합성곱 계층 (Convolution Layer) - 위에서 아래로 순서대로 CNN 작동\n",
    "- 패딩(padding), 스트라이트(Stride)\n",
    "- 필터(Filter, 또는 합성곱 커널)\n",
    "- 특성 맵(Feature map)\n",
    "- 풀링 계층(Pooling Layer)\n",
    "\n",
    "#### 합성곱 계층 특징\n",
    "- 이미지 데이터는 세로, 가로 채널(색상)으로 구성된 데이터\n",
    "- MNIST 데이터는 원래 (1, 28, 28)인 3차원 데이터\n",
    "    -> Affine 계층에 입력 시 (28 * 28 = 784)개의 1차원 입력\n",
    "- 합성곱 계층의 입출력 데이터를 특징 맵 (Feature Map)이라고 함\n",
    "- 합성곱 계층에서 입력 데이터를 3차원으로 입력 받으며, 출력 또한 3차원으로 출력\n",
    "\n",
    "#### 합성곱 계층 - 연산\n",
    "- 합성곱 계층에서 연산 수행 -> 필터(커널) 연산\n",
    "- 데이터와 필터의 형상을 (높이, 너비)로 표기\n",
    "- 윈도우를 일정 간격(Stride)으로 이동하며 계산\n",
    "\n",
    "#### 합성곱 계층 - 패딩(Padding)\n",
    "- 합성곱 연산을 수행하기 전, 입력 데이터 주변을 특정값으로 채우는 것\n",
    "- 패딩은 출력데이터의 공간적 크기를 조절하기 위해 사용\n",
    "- 패딩은 hyperparameter로 어떤 값으로 채울지 결정할 수 있음\n",
    "- Padding을 사용하지 않을 경우, 데이터의 Spatial 크기는 Conv 레이어를 지날 때 마다 작아지게 되고, 가장자리의 정보들이 사라지게 되므로 사용\n",
    "- 대부분 바깥은 0으로\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 스트라이트(Stride)\n",
    "- 필터의 적용하는 위치의 간격\n",
    "- Stride는 출력 데이터의 크기를 조정하기 위해 사용\n",
    "- Stride 값은 보통 1과 같이 작은 값이 더 잘 작동\n",
    "- Stride 값이 1일 경우, 데이터의 Spatial 크기는 Padding 계층에서만 조절 가능\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 필터(Filter)\n",
    "- 추출하려는 이미지의 특징이 대상 데이터에 있는지 없는지 검출해주는 함수\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 특징맵(Feature Map)\n",
    "\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 3차원 데이터의 연산\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 배치처리\n",
    "- 데이터의 차원을 늘려 4차원 데이터로 저장\n",
    "- (데이터 수, 채널 수, 높이, 너비)로 저장\n",
    "\n",
    "\n",
    "\n",
    "#### 합성곱 계층 - 폴링 계층(Pooling Layer)\n",
    "- 데이터의 공간적 크기를 축소하는데 사용\n",
    "- 평균적으로 윈도우 크기와 스트라이드 값은 같은 값으로 설정\n",
    "    - ex) 윈도우 3*3, 스트라이트 3\n",
    "- 합성곱 계층에서도 Padding과 Stride를 통해 출력 데이터의 크기를 조정할 수 있음\n",
    "- Conv 레이어에서는 출력 데이터의 Spatial 크기를 입력 데이터의 크기를 그대로 유지하고, Pooling 계층에서만 Spatial 크기를 조절할 수 있도록 함\n",
    "\n",
    "\n",
    "\n",
    "#### CNN 활용 사례\n",
    "- 이미지 분류(Image Classification) : 개, 고양이, 자동차 등 다양한 객체를 분류\n",
    "- 객체 탐지(Object Detection): 사진 속 특정 객체 위치를 인식 (YOLO, Faster R-CNN)\n",
    "-\n",
    "\n",
    "\n"
   ],
   "id": "1dc96e15ecf35264"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-19T05:15:31.905032Z",
     "start_time": "2025-07-19T05:15:31.729657Z"
    }
   },
   "source": [
    "# MNIST 실습 코드\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# 로컬인경우 표현하실분\n",
    "path = '.'\n",
    "# 코랩인경우\n",
    "# path = '/content/drive/MyDrive/★ 클뉴즈sw/인공지능(AI) 교육/코랩실습/3주차'\n",
    "\n",
    "\n",
    "\n",
    "# MNIST 데이터셋을 불러와 학습셋과 테스트셋으로 저장합니다.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 학습셋과 테스트셋이 각각 몇 개의 이미지로 되어 있는지 확인합니다.\n",
    "print(\"학습셋 이미지 수 : %d 개\" % (X_train.shape[0]))\n",
    "print(\"테스트셋 이미지 수 : %d 개\" % (X_test.shape[0]))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000 개\n",
      "테스트셋 이미지 수 : 10000 개\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MNIST 전처리 과정\n",
    "- Reshape (차원 변환)\n",
    "- 데이터 정규화 (0~1 범위 변환)\n",
    "- 원-핫 인코딩 (레이블 변환)\n",
    "\n",
    "\n",
    "### 데이터 전처리 과정 1 - reshape 통한 차원 변환\n",
    "- MNIST 데이터는 원래 (샘플수, 28, 28) 형태의 2D 이미지\n",
    "- 신경망에서 처리하기 위해 1D 벡터로 변환\n",
    "\n",
    "\n",
    "### 데이터 전처리 과정 2 - 데이터 정규화 (Normalization)\n",
    "- 원본 데이터의 픽셀 값 범위: 0 ~ 255 (8bit grayscale 이미지)\n",
    "- 신경망에서 학습할 때 0 ~ 1 범위의 값이 더 적절 -> 정규화 필요\n",
    "- .astype('float64') -> 정수 데이터를 실수형으로 변환해야 나눗셈이 정상 작동\n",
    "- X_train / 255 -> 픽셀 값을 0 ~ 1 사이 값으로 조정\n",
    "\n",
    "\n",
    "### 데이터 전처리 과정 3 - 원 - 핫 인코딩\n",
    "- to_categorical(y_train, 10)     -> y_train = 클래스, 10 = 클래스 갯수\n",
    "- 0 ~ 9 숫자 레이블을 10차원 벡터로 변환\n",
    "- 원래 y_train[0] = 2 였다면         -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "- 2번째 위치의 값이 1이고, 나머지는 0 (즉, 숫자 2를 나타내는 벡터)"
   ],
   "id": "1ad53a2d086bcdd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 딥러닝 기본 프레임\n",
    "\n",
    "- 딥러닝 실행하기 위한 프레임 설정\n",
    "- 총 784개의 속성과 10개의 클래스가 있기 때문에 다음과 같이 프레임을 작성\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "```\n",
    "- 입력 값이 784개 중 은닉층이 512개, 출력이 10개인 모델로\n",
    "- 활성화 함수는 은닉층에거 relu, 출력층에서 softmax 사용\n",
    "\n",
    "\n",
    "- 이후, 딥러닝 실행 환경을 위한 오차 함수로 categorical_crossentropy, 최적화 함수로 adam 사용\n",
    "\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy', optimize='adam', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "- 모델의 결과를 저장하고 최적화되었다면 학습이 자동으로 중단하도록 설정\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "modelpath = \"./MNIST_MLPhdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "```\n",
    "\n",
    "- 샘플 200개를 모두 30번씩 실행하고, 테스트셋으로 최종 모델의 성과를 측정해 값을 출력\n",
    "\n",
    "```python\n",
    "# 모델 실행\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" %(model.evaluate(X_test, y_tset)[1]))\n",
    "```\n",
    "\n",
    "\n",
    "- 실행 결과를 그래프로 표현하기 위해 오차 활용\n",
    "- 오차 1에서 정확도를 뺀 값\n",
    "- 학습셋의 오차와 테스트셋의 오차를 하나의 그래프로 표현\n"
   ],
   "id": "b65c5fafbfb2af98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNN (컨볼루션 신경망)\n",
    "- 입력된 이미지에서 다시 한 번 특징을 추출하기 위해 커널을 도입하는 기법\n",
    "- 이미지값과 커널과 합곱산 하면 결과는 컨볼루션 층이 발생\n",
    "- 컨볼루션 층 만들 시 입력 데이터의 특징을 대략적으로 추출하여 학습을 진행 할 수 있음\n",
    "- 여러 개의 커널을 통해 컨볼루션 층을 만들 수 있음\n",
    "- 기존 딥러닝 프레임에서 컨볼루션 층 활용\n",
    "- 케라스에서 컨볼루션 층을 추가하는 함수 `Conv2D()`\n",
    "\n",
    "- Con2D(커널의 수, 커널사이즈, 입력 값(행, 열, 색상3 or 흑백(1), 활성화 함수)\n",
    "\n",
    "- 예\n",
    "\n",
    "```python\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    " ```\n",
    "\n",
    "```python\n",
    "# 컨볼루션 신경망의 설정\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "## 맥스풀링, 드롭아웃, 플래튼\n",
    "- 컨볼루션 층을 통해 이미지 특징을 추출\n",
    "- 그럼에도 불구하고, 추출된 특징이 여전히 크거나 복잡시 다시 축소해야함\n",
    "- 이 과정은 풀링 or 서브 샘플링\n",
    "- 풀링 기법\n",
    "    - 맥스 풀링: 일정 구역 안에 최댓값을 추출\n",
    "    - 에버리징 풀링: 평균값을 추출\n",
    "- 맥스 풀링이 보편적으로 사용\n",
    "`MaxPooling2D()`\n",
    "\n",
    "- 단순히 노드나 층이 많아진다고 해서 학습이 좋아지지 않음\n",
    "- 딥러닝 학습 진행 시\n",
    "    - 과적합을 효과적으로 피하는 것이 중요\n",
    "- 드롭아웃 기법\n",
    "    - 간단하면서도 효과적인 방법\n",
    "    - 은닉층에 배치된 노드 중 일부를 임의로 꺼 주는 방법\n",
    "    - 랜덤하게 노드를 비활성화하면서 지나치게 학습되는 과적합 방지 `model.add(Dropout(0.25))`\n",
    "    - 25% 노드를 비활성화, 케라스를 통해 손쉽게 적용\n",
    "- 주의점: 컨보루션 층 or 맥스풀링은 주어진 이미지를 2차원 배일로 다룸\n",
    "- 1차원 배열로 바꿔주는 활성화 함수가 있는 층에서 사용으로 `Flatten()` 함수로 가능\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "5ee96ae173cc5e88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
