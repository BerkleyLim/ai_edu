{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4KzRkr/CiAt1k1Ewhv1lh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7Idq0Mchyzn9"},"outputs":[],"source":["# ==================== 라이브러리 임포트 섹션 ====================\n","# 운영체제 관련 기능을 사용하기 위한 라이브러리\n","import os\n","# 수치 연산을 위한 NumPy 라이브러리\n","import numpy as np\n","# PyTorch 딥러닝 프레임워크의 메인 모듈\n","import torch\n","# PyTorch의 신경망 구성 요소들 (레이어, 손실함수 등)\n","import torch.nn as nn\n","# PyTorch의 최적화 알고리즘들 (SGD, Adam 등)\n","import torch.optim as optim\n","# PyTorch의 컴퓨터 비전 관련 유틸리티\n","import torchvision\n","# 이미지 전처리 및 변환을 위한 모듈\n","import torchvision.transforms as transforms\n","# 데이터를 배치 단위로 로드하기 위한 DataLoader\n","from torch.utils.data import DataLoader\n","# 그래프 및 이미지 시각화를 위한 matplotlib\n","import matplotlib.pyplot as plt\n","# 이미지 처리를 위한 PIL (Python Imaging Library)\n","from PIL import Image\n","# 시간 측정을 위한 time 모듈\n","import time\n","# 랜덤 시드 설정을 위한 random 모듈\n","import random\n","# 파일 경로 패턴 매칭을 위한 glob 모듈\n","import glob\n","# 구글 코랩에서 구글 드라이브 마운트를 위한 모듈\n","from google.colab import drive\n","# 이미지 폴더 구조 기반 데이터셋 로딩을 위한 ImageFolder\n","from torchvision.datasets import ImageFolder\n","# 코랩에서 파일 다운로드를 위한 files 모듈\n","from google.colab import files\n","# 주피터/코랩 환경에서 HTML 표시를 위한 display 모듈\n","from IPython.display import display, HTML\n","\n","# ==================== 구글 드라이브 마운트 섹션 ====================\n","# 구글 드라이브를 '/content/drive' 경로에 마운트하는 시도\n","try:\n","    # 구글 드라이브 마운트 실행\n","    drive.mount('/content/drive')\n","    # 마운트 성공 시 메시지 출력\n","    print(\"구글 드라이브 마운트 성공!\")\n","# 마운트 실패 시 예외 처리\n","except:\n","    # 마운트 실패 또는 사용자가 취소한 경우 메시지 출력\n","    print(\"구글 드라이브 마운트 실패 또는 마운트 취소\")\n","\n","# ==================== 랜덤 시드 설정 섹션 ====================\n","# 재현 가능한 결과를 얻기 위해 모든 랜덤 시드를 고정하는 함수\n","def set_seed(seed):\n","    # Python 기본 random 모듈의 시드 설정\n","    random.seed(seed)\n","    # NumPy의 랜덤 시드 설정\n","    np.random.seed(seed)\n","    # PyTorch CPU 연산의 랜덤 시드 설정\n","    torch.manual_seed(seed)\n","    # CUDA(GPU)가 사용 가능한지 확인\n","    if torch.cuda.is_available():\n","        # 모든 GPU 장치의 랜덤 시드 설정\n","        torch.cuda.manual_seed_all(seed)\n","        # CUDA 연산을 결정론적으로 만들어 완전한 재현성 보장\n","        torch.backends.cudnn.deterministic = True\n","\n","# 시드 값을 42로 설정하여 함수 호출\n","set_seed(42)\n","\n","# ==================== 장치 설정 섹션 ====================\n","# CUDA가 사용 가능하면 GPU, 아니면 CPU를 학습 장치로 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# 사용할 장치 정보 출력\n","print(f\"사용 장치: {device}\")\n","\n","# ==================== 하이퍼파라미터 설정 섹션 ====================\n","# 한 번의 학습 반복(iteration)에서 처리할 이미지의 개수\n","batch_size = 64\n","# 생성할 이미지의 크기 (64x64 픽셀)\n","image_size = 64\n","# 생성자 네트워크의 입력 노이즈 벡터의 차원 수\n","nz = 100\n","# 생성자 네트워크의 특성 맵(feature map) 크기 조절 파라미터\n","ngf = 64\n","# 판별자 네트워크의 특성 맵 크기 조절 파라미터\n","ndf = 64\n","# 전체 데이터셋을 몇 번 반복해서 학습할지 결정하는 에폭 수\n","num_epochs = 50\n","# 경사하강법의 학습률 (너무 크면 불안정, 너무 작으면 학습 느림)\n","lr = 0.0003\n","# Adam 옵티마이저의 첫 번째 모멘텀 계수 (일반적으로 0.9이지만 GAN에서는 0.5 사용)\n","beta1 = 0.5\n","\n","# ==================== 강아지 데이터셋 다운로드 함수 ====================\n","# CIFAR-10 데이터셋에서 강아지 이미지만 추출하여 저장하는 함수\n","def download_dog_dataset():\n","    # 사용자에게 다운로드 시작을 알리는 메시지 출력\n","    print(\"강아지 데이터셋 다운로드 중...\")\n","\n","    # torchvision의 datasets 모듈을 지역적으로 임포트\n","    import torchvision.datasets as datasets\n","\n","    # CIFAR-10 데이터셋을 './cifar10' 폴더에 다운로드 (train=True: 훈련 데이터)\n","    cifar10 = datasets.CIFAR10(root='./cifar10', download=True, train=True)\n","\n","    # CIFAR-10의 10개 클래스 라벨 목록을 가져옴\n","    class_labels = cifar10.classes\n","    # 클래스 목록을 출력하여 사용자에게 확인시켜줌\n","    print(f\"CIFAR-10 클래스 목록: {class_labels}\")\n","\n","    # 'dog' 클래스의 인덱스를 찾음 (CIFAR-10에서 강아지는 인덱스 5)\n","    dog_idx = class_labels.index('dog')\n","    # 찾은 강아지 클래스 인덱스를 출력\n","    print(f\"강아지 클래스 인덱스: {dog_idx}\")\n","\n","    # 강아지 이미지들을 저장할 빈 리스트 초기화\n","    dog_images = []\n","\n","    # CIFAR-10 데이터셋의 모든 이미지를 순회\n","    for i in range(len(cifar10)):\n","        # i번째 이미지와 라벨을 가져옴\n","        img, label = cifar10[i]\n","        # 라벨이 강아지 인덱스와 같은지 확인\n","        if label == dog_idx:\n","            # 강아지 이미지면 리스트에 추가\n","            dog_images.append(img)\n","\n","    # 추출된 강아지 이미지 개수를 출력\n","    print(f\"{len(dog_images)}개의 강아지 이미지를 추출했습니다.\")\n","\n","    # 강아지 이미지를 저장할 폴더 생성 (exist_ok=True: 이미 존재해도 오류 없음)\n","    os.makedirs('./dog_dataset/dogs', exist_ok=True)\n","\n","    # 추출된 모든 강아지 이미지를 파일로 저장\n","    for i, img in enumerate(dog_images):\n","        # i번째 강아지 이미지를 JPEG 형식으로 저장\n","        img.save(f'./dog_dataset/dogs/dog_{i}.jpg')\n","\n","    # 저장 완료 메시지 출력\n","    print(f\"이미지를 './dog_dataset/dogs/' 폴더에 저장했습니다.\")\n","    # 저장된 데이터셋의 루트 경로 반환\n","    return './dog_dataset'\n","\n","# ==================== 데이터셋 확인 및 로드 섹션 ====================\n","# 데이터셋 존재 여부를 확인하고 필요시 다운로드하는 시도\n","try:\n","    # './dog_dataset' 폴더가 존재하지 않거나 jpg 파일이 없는지 확인\n","    if not os.path.exists('./dog_dataset') or len(glob.glob('./dog_dataset/*/*.jpg')) == 0:\n","        # 조건에 해당하면 데이터셋 다운로드 함수 호출\n","        data_root = download_dog_dataset()\n","    # 데이터셋이 이미 존재하는 경우\n","    else:\n","        # 기존 데이터셋 경로를 사용\n","        data_root = './dog_dataset'\n","        # 기존 데이터셋 사용 메시지 출력\n","        print(f\"기존 데이터셋 사용: {data_root}\")\n","# 데이터셋 확인 중 오류가 발생한 경우\n","except:\n","    # 오류 발생 알림 메시지 출력\n","    print(\"데이터셋 확인 중 오류 발생, 다운로드를 시도합니다.\")\n","    # 강제로 데이터셋 다운로드 함수 호출\n","    data_root = download_dog_dataset()\n","\n","# ==================== 이미지 전처리 변환 정의 섹션 ====================\n","# 이미지 전처리 파이프라인을 정의 (여러 변환을 순차적으로 적용)\n","transform = transforms.Compose([\n","    # 이미지 크기를 image_size x image_size로 조정 (비율 유지하며 리사이즈)\n","    transforms.Resize(image_size),\n","    # 이미지 중앙 부분을 image_size x image_size로 잘라내기\n","    transforms.CenterCrop(image_size),\n","    # PIL 이미지를 PyTorch 텐서로 변환 (값 범위: [0, 1])\n","    transforms.ToTensor(),\n","    # 픽셀 값을 [-1, 1] 범위로 정규화 (평균=0.5, 표준편차=0.5)\n","    # 공식: output = (input - mean) / std = (input - 0.5) / 0.5\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","# ==================== 데이터셋 로드 및 DataLoader 생성 섹션 ====================\n","# 이미지 폴더 기반 데이터셋 로드 시도\n","try:\n","    # ImageFolder를 사용하여 폴더 구조 기반으로 데이터셋 생성\n","    dataset = ImageFolder(root=data_root, transform=transform)\n","    # DataLoader 생성: 배치 단위로 데이터 로드, 셔플링, 멀티프로세싱\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    # 데이터셋 로드 완료 메시지와 총 이미지 수 출력\n","    print(f\"데이터셋 로드 완료: {len(dataset)} 이미지\")\n","# 데이터셋 로드 중 예외 발생시 처리\n","except Exception as e:\n","    # 발생한 오류 내용 출력\n","    print(f\"데이터셋 로드 오류: {e}\")\n","    # 임시 방편으로 랜덤 데이터 사용 안내\n","    print(\"임의 데이터로 코드를 계속 실행합니다...\")\n","\n","    # 랜덤 데이터셋을 생성하는 내부 함수 정의\n","    def create_random_dataset(num_samples=1000):\n","        # 정규분포 랜덤 노이즈로 이미지 형태 데이터 생성\n","        random_data = torch.randn(num_samples, 3, image_size, image_size)\n","        # 값을 적절한 범위로 조정하고 [0, 1] 범위로 클램핑\n","        random_data = torch.clamp((random_data * 0.2) + 0.5, 0, 1)\n","        # (이미지, 라벨) 튜플 형태의 리스트 생성 (라벨은 임의로 0)\n","        random_dataset = [(img, 0) for img in random_data]\n","        # 생성된 랜덤 데이터셋 반환\n","        return random_dataset\n","\n","    # PyTorch Dataset 클래스를 상속한 커스텀 랜덤 데이터셋 클래스\n","    class RandomDataset(torch.utils.data.Dataset):\n","        # 생성자: 데이터를 받아서 저장\n","        def __init__(self, data):\n","            self.data = data\n","\n","        # 데이터셋 크기 반환 메서드\n","        def __len__(self):\n","            return len(self.data)\n","\n","        # 인덱스에 해당하는 데이터 항목 반환 메서드\n","        def __getitem__(self, idx):\n","            return self.data[idx]\n","\n","    # 랜덤 데이터셋 객체 생성\n","    random_dataset = RandomDataset(create_random_dataset())\n","    # 랜덤 데이터셋용 DataLoader 생성\n","    dataloader = DataLoader(random_dataset, batch_size=batch_size, shuffle=True)\n","    # 랜덤 데이터셋 생성 완료 메시지 출력\n","    print(f\"임의 데이터셋 생성 완료: {len(random_dataset)} 이미지\")\n","\n","# ==================== 가중치 초기화 함수 섹션 ====================\n","# DCGAN 논문에서 권장하는 가중치 초기화 함수\n","def weights_init(m):\n","    # 모듈의 클래스 이름을 문자열로 가져옴\n","    classname = m.__class__.__name__\n","    # 클래스 이름에 'Conv'가 포함되어 있으면 (Convolution 레이어)\n","    if classname.find('Conv') != -1:\n","        # 가중치를 평균 0.0, 표준편차 0.02인 정규분포로 초기화\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    # 클래스 이름에 'BatchNorm'이 포함되어 있으면 (Batch Normalization 레이어)\n","    elif classname.find('BatchNorm') != -1:\n","        # 가중치를 평균 1.0, 표준편차 0.02인 정규분포로 초기화\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        # bias를 0으로 초기화\n","        nn.init.constant_(m.bias.data, 0)\n","\n","# ==================== Generator 모델 정의 섹션 ====================\n","# 노이즈 벡터를 이미지로 변환하는 생성자 네트워크 클래스\n","class Generator(nn.Module):\n","    # 생성자 메서드\n","    def __init__(self):\n","        # 부모 클래스 초기화\n","        super(Generator, self).__init__()\n","        # Sequential 컨테이너로 레이어들을 순차적으로 연결\n","        self.main = nn.Sequential(\n","            # 첫 번째 전치 합성곱 레이어: nz(100) -> ngf*8(512) 채널\n","            # 입력: (배치크기, 100, 1, 1) -> 출력: (배치크기, 512, 4, 4)\n","            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n","            # 배치 정규화로 학습 안정성 향상\n","            nn.BatchNorm2d(ngf * 8),\n","            # ReLU 활성화 함수 (inplace=True: 메모리 효율성)\n","            nn.ReLU(True),\n","\n","            # 두 번째 전치 합성곱 레이어: ngf*8(512) -> ngf*4(256) 채널\n","            # 입력: (배치크기, 512, 4, 4) -> 출력: (배치크기, 256, 8, 8)\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ngf * 4),\n","            # ReLU 활성화 함수\n","            nn.ReLU(True),\n","\n","            # 세 번째 전치 합성곱 레이어: ngf*4(256) -> ngf*2(128) 채널\n","            # 입력: (배치크기, 256, 8, 8) -> 출력: (배치크기, 128, 16, 16)\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ngf * 2),\n","            # ReLU 활성화 함수\n","            nn.ReLU(True),\n","\n","            # 네 번째 전치 합성곱 레이어: ngf*2(128) -> ngf(64) 채널\n","            # 입력: (배치크기, 128, 16, 16) -> 출력: (배치크기, 64, 32, 32)\n","            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ngf),\n","            # ReLU 활성화 함수\n","            nn.ReLU(True),\n","\n","            # 마지막 전치 합성곱 레이어: ngf(64) -> 3(RGB) 채널\n","            # 입력: (배치크기, 64, 32, 32) -> 출력: (배치크기, 3, 64, 64)\n","            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n","            # Tanh 활성화 함수로 출력을 [-1, 1] 범위로 제한\n","            nn.Tanh()\n","        )\n","\n","    # 순전파 메서드: 입력을 네트워크에 통과시켜 출력 생성\n","    def forward(self, input):\n","        # Sequential 네트워크에 입력을 통과시킨 결과 반환\n","        return self.main(input)\n","\n","# ==================== Discriminator 모델 정의 섹션 ====================\n","# 이미지가 진짜인지 가짜인지 판별하는 판별자 네트워크 클래스\n","class Discriminator(nn.Module):\n","    # 생성자 메서드\n","    def __init__(self):\n","        # 부모 클래스 초기화\n","        super(Discriminator, self).__init__()\n","        # Sequential 컨테이너로 레이어들을 순차적으로 연결\n","        self.main = nn.Sequential(\n","            # 첫 번째 합성곱 레이어: 3(RGB) -> ndf(64) 채널\n","            # 입력: (배치크기, 3, 64, 64) -> 출력: (배치크기, 64, 32, 32)\n","            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n","            # LeakyReLU 활성화 함수 (음수 기울기 0.2, inplace=True)\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # 두 번째 합성곱 레이어: ndf(64) -> ndf*2(128) 채널\n","            # 입력: (배치크기, 64, 32, 32) -> 출력: (배치크기, 128, 16, 16)\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ndf * 2),\n","            # LeakyReLU 활성화 함수\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # 세 번째 합성곱 레이어: ndf*2(128) -> ndf*4(256) 채널\n","            # 입력: (배치크기, 128, 16, 16) -> 출력: (배치크기, 256, 8, 8)\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ndf * 4),\n","            # LeakyReLU 활성화 함수\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # 네 번째 합성곱 레이어: ndf*4(256) -> ndf*8(512) 채널\n","            # 입력: (배치크기, 256, 8, 8) -> 출력: (배치크기, 512, 4, 4)\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            # 배치 정규화\n","            nn.BatchNorm2d(ndf * 8),\n","            # LeakyReLU 활성화 함수\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            # 마지막 합성곱 레이어: ndf*8(512) -> 1 채널\n","            # 입력: (배치크기, 512, 4, 4) -> 출력: (배치크기, 1, 1, 1)\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            # Sigmoid 활성화 함수로 출력을 [0, 1] 확률값으로 변환\n","            nn.Sigmoid()\n","        )\n","\n","    # 순전파 메서드: 이미지를 입력받아 진짜/가짜 확률 반환\n","    def forward(self, input):\n","        # 네트워크 출력을 1차원으로 변환하여 확률값 반환\n","        # view(-1, 1): (배치크기, 1, 1, 1) -> (배치크기, 1)\n","        # squeeze(1): (배치크기, 1) -> (배치크기,)\n","        return self.main(input).view(-1, 1).squeeze(1)\n","\n","# ==================== 모델 객체 생성 및 초기화 섹션 ====================\n","# 생성자 네트워크 객체 생성 및 지정된 장치로 이동\n","netG = Generator().to(device)\n","# 판별자 네트워크 객체 생성 및 지정된 장치로 이동\n","netD = Discriminator().to(device)\n","\n","# 생성자 네트워크의 모든 레이어에 가중치 초기화 함수 적용\n","netG.apply(weights_init)\n","# 판별자 네트워크의 모든 레이어에 가중치 초기화 함수 적용\n","netD.apply(weights_init)\n","\n","# 생성자 모델 구조 출력\n","print(\"생성자 모델 구조:\")\n","print(netG)\n","# 판별자 모델 구조 출력\n","print(\"\\n판별자 모델 구조:\")\n","print(netD)\n","\n","# ==================== 손실 함수 및 옵티마이저 설정 섹션 ====================\n","# 이진 교차 엔트로피 손실 함수 (GAN의 표준 손실 함수)\n","criterion = nn.BCELoss()\n","\n","# 학습 중 생성 품질 확인용 고정 노이즈 벡터 생성\n","# (64개 샘플, nz 차원, 1x1 크기, 지정된 장치에 배치)\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# 진짜 이미지에 대한 라벨 값 (1: 진짜)\n","real_label = 1\n","# 가짜 이미지에 대한 라벨 값 (0: 가짜)\n","fake_label = 0\n","\n","# 판별자용 Adam 옵티마이저 생성 (학습률 lr, 베타 파라미터 설정)\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","# 생성자용 Adam 옵티마이저 생성\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","# ==================== 이미지 시각화 함수 섹션 ====================\n","# 이미지 텐서를 시각화하는 함수\n","def visualize_images(images, title=None, display_in_notebook=True):\n","    # 이미지 픽셀값을 [-1, 1] 범위에서 [0, 1] 범위로 변환\n","    images = (images + 1) / 2.0\n","\n","    # 여러 이미지를 격자 형태로 배열 (패딩 2픽셀, 정규화 없음)\n","    grid = torchvision.utils.make_grid(images, padding=2, normalize=False)\n","    # PyTorch 텐서를 numpy 배열로 변환하고 채널 순서 변경\n","    # (채널, 높이, 너비) -> (높이, 너비, 채널)\n","    img = grid.permute(1, 2, 0).cpu().numpy()\n","\n","    # matplotlib 그림 생성 (8x8 인치 크기)\n","    plt.figure(figsize=(8, 8))\n","    # 이미지 배열을 화면에 표시\n","    plt.imshow(img)\n","    # 제목이 제공된 경우 설정\n","    if title:\n","        plt.title(title)\n","    # 축 눈금과 라벨 숨기기\n","    plt.axis('off')\n","\n","    # 노트북 환경에서 이미지 표시 여부 결정\n","    if display_in_notebook:\n","        plt.show()\n","\n","    # 처리된 이미지 배열 반환\n","    return img\n","\n","# ==================== 결과 저장 폴더 생성 섹션 ====================\n","# 학습 결과 이미지를 저장할 'results' 폴더 생성\n","os.makedirs(\"results\", exist_ok=True)\n","# 모델 체크포인트를 저장할 'checkpoints' 폴더 생성\n","os.makedirs(\"checkpoints\", exist_ok=True)\n","\n","# ==================== 학습 기록 리스트 초기화 섹션 ====================\n","# 생성자 손실값들을 저장할 리스트\n","G_losses = []\n","# 판별자 손실값들을 저장할 리스트\n","D_losses = []\n","# 각 에폭별 생성된 이미지들을 저장할 리스트\n","img_list = []\n","\n","# 학습 시작 알림 메시지\n","print(\"학습 시작...\")\n","\n","# ==================== 프로그레스 바 함수 섹션 ====================\n","# 학습 진행률을 시각적으로 보여주는 프로그레스 바 함수\n","def progress_bar(current, total, bar_length=50):\n","    # 전체 작업 중 현재 진행된 비율 계산\n","    fraction = current / total\n","    # 진행된 부분을 '=' 문자로 표현\n","    arrow = int(fraction * bar_length) * '='\n","    # 남은 부분을 공백으로 표현\n","    padding = (bar_length - len(arrow)) * ' '\n","    # 프로그레스 바 문자열 생성 및 반환\n","    return f\"[{arrow}{padding}] {int(fraction * 100)}%\"\n","\n","# ==================== GAN 학습 메인 루프 섹션 ====================\n","# 에폭 수만큼 반복하는 메인 학습 루프\n","for epoch in range(num_epochs):\n","    # 현재 에폭의 시작 시간 기록\n","    start_time = time.time()\n","\n","    # 데이터로더에서 배치 단위로 데이터를 순회\n","    for i, data in enumerate(dataloader, 0):\n","\n","        # ==================== 판별자 학습 파트 ====================\n","        # 판별자의 그래디언트를 0으로 초기화\n","        netD.zero_grad()\n","\n","        # 데이터가 리스트 형태인지 확인하고 실제 이미지 추출\n","        if isinstance(data, list) and len(data) == 2:\n","            # 첫 번째 요소가 이미지라고 가정하고 장치로 이동\n","            real_cpu = data[0].to(device)\n","        else:\n","            # 데이터가 직접 이미지 텐서인 경우\n","            real_cpu = data[0].to(device)\n","\n","        # 현재 배치의 크기 확인\n","        batch_size = real_cpu.size(0)\n","        # 진짜 이미지에 대한 라벨 텐서 생성 (모든 값이 real_label=1)\n","        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n","\n","        # 진짜 이미지를 판별자에 통과시켜 예측값 얻기\n","        output = netD(real_cpu)\n","        # 진짜 이미지에 대한 판별자 손실 계산\n","        errD_real = criterion(output, label)\n","        # 역전파로 그래디언트 계산\n","        errD_real.backward()\n","        # 판별자가 진짜 이미지를 진짜로 예측한 평균 확률 저장\n","        D_x = output.mean().item()\n","\n","        # 생성자 입력용 랜덤 노이즈 벡터 생성\n","        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n","        # 생성자로 가짜 이미지 생성\n","        fake = netG(noise)\n","        # 가짜 이미지에 대한 라벨을 fake_label=0으로 설정\n","        label.fill_(fake_label)\n","\n","        # 가짜 이미지를 판별자에 통과 (.detach()로 생성자 그래디언트 차단)\n","        output = netD(fake.detach())\n","        # 가짜 이미지에 대한 판별자 손실 계산\n","        errD_fake = criterion(output, label)\n","        # 역전파로 그래디언트 계산\n","        errD_fake.backward()\n","        # 판별자가 가짜 이미지를 진짜로 잘못 예측한 평균 확률 저장\n","        D_G_z1 = output.mean().item()\n","\n","        # 판별자의 총 손실 = 진짜 이미지 손실 + 가짜 이미지 손실\n","        errD = errD_real + errD_fake\n","        # 판별자 가중치 업데이트\n","        optimizerD.step()\n","\n","        # ==================== 생성자 학습 파트 ====================\n","        # 생성자의 그래디언트를 0으로 초기화\n","        netG.zero_grad()\n","        # 생성자 학습용: 가짜 이미지의 라벨을 real_label=1로 설정\n","        # (생성자는 판별자가 가짜를 진짜로 착각하게 만들고 싶어함)\n","        label.fill_(real_label)\n","\n","        # 생성자가 만든 가짜 이미지를 다시 판별자에 통과\n","        output = netD(fake)\n","        # 생성자 손실 계산 (판별자가 가짜를 진짜로 판단하길 원함)\n","        errG = criterion(output, label)\n","        # 역전파로 생성자 그래디언트 계산\n","        errG.backward()\n","        # 생성자 학습 후 판별자가 가짜를 진짜로 예측한 평균 확률\n","        D_G_z2 = output.mean().item()\n","\n","        # 생성자 가중치 업데이트\n","        optimizerG.step()\n","\n","        # ==================== 손실 기록 및 진행상황 출력 섹션 ====================\n","        # 현재 배치의 손실값들을 리스트에 추가\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        # 10 배치마다 진행 상황 출력\n","        if i % 10 == 0:\n","            # 프로그레스 바 문자열 생성\n","            prog = progress_bar(i, len(dataloader))\n","            # 현재 에폭, 배치, 손실값들, 판별 확률들을 한 줄에 출력\n","            print(f'\\r에폭 [{epoch+1}/{num_epochs}] 배치 {prog} '\n","                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n","                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}', end='')\n","\n","    # 에폭 완료 후 줄바꿈\n","    print(' ')\n","\n","    # ==================== 에폭별 이미지 생성 및 저장 섹션 ====================\n","    # 그래디언트 계산을 비활성화하여 메모리 절약\n","    with torch.no_grad():\n","        # 고정된 노이즈로 이미지 생성하고 CPU로 이동\n","        fake = netG(fixed_noise).detach().cpu()\n","\n","    # 생성된 이미지를 리스트에 추가 (학습 진행 과정 추적용)\n","    img_list.append(fake)\n","\n","    # 생성된 이미지를 시각화\n","    img = visualize_images(fake, title=f'epoch {epoch+1} Result')\n","\n","    # 결과 이미지를 PNG 파일로 저장\n","    plt.savefig(f'results/fake_dogs_epoch_{epoch+1}.png')\n","    # 현재 플롯을 닫아 메모리 해제\n","    plt.close()\n","\n","    # ==================== 모델 체크포인트 저장 섹션 ====================\n","    # 5 에폭마다 또는 마지막 에폭에서 모델 저장\n","    if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n","        # 모델 상태, 옵티마이저 상태, 손실 기록 등을 딕셔너리로 저장\n","        torch.save({\n","            'generator': netG.state_dict(),        # 생성자 가중치\n","            'discriminator': netD.state_dict(),    # 판별자 가중치\n","            'optimizerG': optimizerG.state_dict(), # 생성자 옵티마이저 상태\n","            'optimizerD': optimizerD.state_dict(), # 판별자 옵티마이저 상태\n","            'epoch': epoch,                        # 현재 에폭 번호\n","            'G_losses': G_losses,                  # 생성자 손실 기록\n","            'D_losses': D_losses,                  # 판별자 손실 기록\n","        }, f'checkpoints/gan_model_epoch_{epoch+1}.pth')\n","        # 체크포인트 저장 완료 메시지\n","        print(f\"모델 체크포인트 저장: 에폭 {epoch+1}\")\n","\n","    # ==================== 에폭 소요시간 계산 및 출력 섹션 ====================\n","    # 현재 에폭의 소요 시간 계산\n","    elapsed = time.time() - start_time\n","    # 에폭 완료 및 소요 시간 출력\n","    print(f'에폭 {epoch+1} 완료, 소요 시간: {elapsed:.2f}초')\n","\n","# 전체 학습 완료 메시지\n","print(\"학습 완료!\")\n","\n","# ==================== 손실 그래프 시각화 섹션 ====================\n","# 손실 그래프를 그리기 위한 figure 생성\n","plt.figure(figsize=(10, 5))\n","# 그래프 제목 설정\n","plt.title(\"Loss of Generator and Discriminator\")\n","# 생성자 손실을 선 그래프로 플롯\n","plt.plot(G_losses, label=\"Generator\")\n","# 판별자 손실을 선 그래프로 플롯\n","plt.plot(D_losses, label=\"Discriminator\")\n","# x축 라벨 설정\n","plt.xlabel(\"Repeat\")\n","# y축 라벨 설정\n","plt.ylabel(\"Loss\")\n","# 범례 표시\n","plt.legend()\n","# 그래프를 PNG 파일로 저장\n","plt.savefig('results/loss_plot.png')\n","# 그래프를 화면에 표시\n","plt.show()\n","# 현재 플롯 닫기\n","plt.close()\n","\n","# ==================== 학습 진행 과정 시각화 섹션 ====================\n","# 각 에폭별 생성 이미지들을 그리드로 시각화\n","plt.figure(figsize=(12, 12))\n","# 그리드의 행 수 계산 (제곱근 이용)\n","rows = int(np.sqrt(num_epochs))\n","# 그리드의 열 수 계산 (올림 이용)\n","cols = int(np.ceil(num_epochs / rows))\n","\n","# 에폭 수 또는 저장된 이미지 수 중 작은 값만큼 반복\n","for i in range(min(num_epochs, len(img_list))):\n","    # 서브플롯 위치 설정 (i+1번째 위치)\n","    plt.subplot(rows, cols, i + 1)\n","    # 축 숨기기\n","    plt.axis('off')\n","    # 서브플롯 제목 설정 (에폭 번호)\n","    plt.title(f'epoch {i+1}')\n","\n","    # 저장된 이미지가 있는 경우에만 처리\n","    if i < len(img_list):\n","        # 해당 에폭의 이미지 중 처음 16개만 격자로 배열\n","        img = torchvision.utils.make_grid(img_list[i][:16], padding=2, normalize=True)\n","        # 텐서를 numpy 배열로 변환하고 채널 순서 변경하여 표시\n","        plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n","\n","# 서브플롯 간 간격 자동 조정\n","plt.tight_layout()\n","# 전체 진행 과정 이미지를 파일로 저장\n","plt.savefig('results/progress.png')\n","# 화면에 표시\n","plt.show()\n","\n","# ==================== 새 이미지 생성 함수 섹션 ====================\n","# 학습된 생성자로 새로운 이미지를 생성하는 함수\n","def generate_new_dogs(num_images=16):\n","    # 생성자를 평가 모드로 설정 (Dropout, BatchNorm 등 비활성화)\n","    netG.eval()\n","\n","    # 그래디언트 계산 비활성화\n","    with torch.no_grad():\n","        # 새로운 랜덤 노이즈 벡터 생성\n","        noise = torch.randn(num_images, nz, 1, 1, device=device)\n","\n","        # 생성자로 새 가짜 이미지 생성 후 CPU로 이동\n","        fake_dogs = netG(noise).detach().cpu()\n","\n","        # 생성된 이미지들을 시각화\n","        visualize_images(fake_dogs, title=f'Generated Dog Image {num_images}')\n","        # 최종 생성 이미지를 파일로 저장\n","        plt.savefig('results/final_generated_dogs.png')\n","\n","        # 생성 완료 메시지 출력\n","        print(f\"{num_images}개의 새로운 강아지 이미지를 생성했습니다. ('results/final_generated_dogs.png'에 저장)\")\n","\n","        # 생성된 이미지 데이터 반환\n","        return fake_dogs\n","\n","# ==================== 최종 이미지 생성 섹션 ====================\n","# 최종 모델 이미지 생성 안내 메시지\n","print(\"\\n최종 모델로 새 이미지 생성:\")\n","# 16개의 새로운 강아지 이미지 생성\n","generate_new_dogs(16)\n","\n","# ==================== 결과 다운로드 안내 함수 섹션 ====================\n","# 생성된 결과 파일들을 다운로드하는 방법을 안내하는 함수\n","def download_results():\n","    # 다운로드 방법 안내 메시지들 출력\n","    print(\"\\n생성된 결과 다운로드:\")\n","    print(\"1. 왼쪽 사이드바에서 파일 탭(📁)을 클릭합니다.\")\n","    print(\"2. 'results' 폴더에서 생성된 이미지를 다운로드합니다.\")\n","    print(\"또는 아래 코드를 실행하여 결과 파일을 다운로드할 수 있습니다:\")\n","    print(\"files.download('results/final_generated_dogs.png')\")\n","    print(\"files.download('results/progress.png')\")\n","    print(\"files.download('results/loss_plot.png')\")\n","\n","# ==================== 실습 완료 섹션 ====================\n","# 실습 완료 메시지 출력\n","print(\"\\n=== GAN 실습2 완료 ===\")\n","print(\"생성된 모든 결과는 'results' 폴더에 저장되었습니다.\")\n","# 결과 다운로드 안내 함수 호출\n","download_results()"]}]}