{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "-jzZaBcw0xbN",
    "ExecuteTime": {
     "end_time": "2025-08-23T07:23:27.636756Z",
     "start_time": "2025-08-23T07:23:27.264818Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 화면을 보고 실습 코드를 작성해주세요."
   ],
   "metadata": {
    "id": "5RTjx57-Rbeu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class LSTMCell:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.W_f = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_f = np.zeros((hidden_size, 1))\n",
    "\n",
    "        self.W_i = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_i = np.zeros((hidden_size, 1))\n",
    "\n",
    "        self.W_C = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_C = np.zeros((hidden_size, 1))\n",
    "\n",
    "        self.W_o = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_o = np.zeros((hidden_size, 1))\n"
   ],
   "metadata": {
    "id": "oQACRBA400BW",
    "ExecuteTime": {
     "end_time": "2025-08-23T07:23:28.066641Z",
     "start_time": "2025-08-23T07:23:28.062376Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "        def sigmoid(self, x):\n",
    "          return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def tanh(self, x):\n",
    "          return np.tanh(x)\n"
   ],
   "metadata": {
    "id": "pmw08rqe07Ft",
    "ExecuteTime": {
     "end_time": "2025-08-23T07:23:30.331573Z",
     "start_time": "2025-08-23T07:23:30.328457Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 화면을 보고 실습 코드를 작성해주세요."
   ],
   "metadata": {
    "id": "PWg2fRC-R3UV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "        def forward(self, x_t, h_prev, C_prev):\n",
    "          \"\"\"\n",
    "          LSTM셀의 순전파 연산 수행\n",
    "          :param x_t: 현재 입력 (shape: input_size)\n",
    "          :param h_prev: 이전 은닉 상태 (shape: hidden_size)\n",
    "          :param C_prev: 이전 셀 상태 (shape: hidden_size)\n",
    "          :return: h_t, C_t (현재 은닉 상태와 셀 상태)\n",
    "          \"\"\"\n",
    "\n",
    "          # 입력과 이전 은닉 상태를 연결\n",
    "          concat = np.vstack((h_prev, x_t))  # (hidden_size + input_size, 1)\n",
    "\n",
    "          # 망각 게이트\n",
    "          f_t = self.sigmoid(np.dot(self.W_f, concat) + self.b_f)\n",
    "\n",
    "          # 입력 게이트\n",
    "          i_t = self.sigmoid(np.dot(self.W_i, concat) + self.b_i)\n",
    "          C_tilde = self.tanh(np.dot(self.W_C, concat) + self.b_C)\n",
    "\n",
    "          # 새로운 셀 상태\n",
    "          C_t = f_t * C_prev + i_t * C_tilde\n",
    "\n",
    "          # 출력 게이트\n",
    "          o_t = self.sigmoid(np.dot(self.W_o, concat) + self.b_o)\n",
    "          h_t = o_t * self.tanh(C_t)\n",
    "\n",
    "          return h_t, C_t, f_t, i_t, o_t, C_tilde\n",
    "\n",
    "\n",
    "          # 입력 차원 및 은닉 상태 차원 정의\n",
    "          input_size = 3\n",
    "          hidden_size = 5\n",
    "          seq_length = 10  # 시퀀스 길이\n",
    "\n",
    "          # LSTM 셀 초기화\n",
    "          lstm_cell = LSTMCell(input_size, hidden_size)\n",
    "\n",
    "          # 초기 은닉 상태 및 셀 상태\n",
    "          h_t = np.zeros((hidden_size, 1))\n",
    "          C_t = np.zeros((hidden_size, 1))\n",
    "\n",
    "          # 더미 입력 데이터 (랜덤)\n",
    "          np.random.seed(0)\n",
    "          inputs = [np.random.randn(input_size, 1) for _ in range(seq_length)]\n",
    "\n",
    "          # 시퀀스 처리 및 값 저장\n",
    "          h_states = []\n",
    "          C_states = []\n",
    "          forget_gates = []\n",
    "          input_gates = []\n",
    "          output_gates = []\n",
    "          cell_candidates = []\n",
    "\n",
    "          for x_t in inputs:\n",
    "            h_t, C_t, f_t, i_t, o_t, C_tilde = lstm_cell.forward(x_t, h_t, C_t)\n",
    "            h_states.append(h_t.flatten())\n",
    "            C_states.append(C_t.flatten())\n",
    "            forget_gates.append(f_t.flatten())\n",
    "            input_gates.append(i_t.flatten())\n",
    "            output_gates.append(o_t.flatten())\n",
    "            cell_candidates.append(C_tilde.flatten())\n",
    "\n"
   ],
   "metadata": {
    "id": "kchkuM1Q1CJq",
    "ExecuteTime": {
     "end_time": "2025-08-23T07:54:06.155008Z",
     "start_time": "2025-08-23T07:54:06.138873Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input\n"
   ],
   "metadata": {
    "id": "LZiFg9wL1Ivi",
    "ExecuteTime": {
     "end_time": "2025-08-23T07:31:33.334103Z",
     "start_time": "2025-08-23T07:31:21.034056Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 화면을 보고 실습 코드를 작성해주세요."
   ],
   "metadata": {
    "id": "ObvHEE2GSY6C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#  애플(AAPL) 주가 데이터 다운로드\n",
    "stock_data = yf.download('AAPL', start='2020-01-01', end='2024-01-01')\n",
    "data = stock_data[['Close']].values\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZuvWqrm1zbG",
    "outputId": "8f1e4b9a-2faa-4b9f-da6a-5d5be9bf6fcb",
    "ExecuteTime": {
     "end_time": "2025-08-23T08:10:37.115553Z",
     "start_time": "2025-08-23T08:10:35.544838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# 데이터 정규화\u001B[39;00m\n\u001B[32m      6\u001B[39m scaler = MinMaxScaler(feature_range=(\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m))\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m data_scaled = \u001B[43mscaler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    321\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    322\u001B[39m         return_tuple = (\n\u001B[32m    323\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    324\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    325\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/base.py:918\u001B[39m, in \u001B[36mTransformerMixin.fit_transform\u001B[39m\u001B[34m(self, X, y, **fit_params)\u001B[39m\n\u001B[32m    903\u001B[39m         warnings.warn(\n\u001B[32m    904\u001B[39m             (\n\u001B[32m    905\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) has a `transform`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    913\u001B[39m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[32m    914\u001B[39m         )\n\u001B[32m    916\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    917\u001B[39m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m.transform(X)\n\u001B[32m    919\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    920\u001B[39m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:447\u001B[39m, in \u001B[36mMinMaxScaler.fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    445\u001B[39m \u001B[38;5;66;03m# Reset internal state before fitting\u001B[39;00m\n\u001B[32m    446\u001B[39m \u001B[38;5;28mself\u001B[39m._reset()\n\u001B[32m--> \u001B[39m\u001B[32m447\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpartial_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:487\u001B[39m, in \u001B[36mMinMaxScaler.partial_fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m    484\u001B[39m xp, _ = get_namespace(X)\n\u001B[32m    486\u001B[39m first_pass = \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mn_samples_seen_\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m487\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfirst_pass\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_array_api\u001B[49m\u001B[43m.\u001B[49m\u001B[43msupported_float_dtypes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    495\u001B[39m data_min = _array_api._nanmin(X, axis=\u001B[32m0\u001B[39m, xp=xp)\n\u001B[32m    496\u001B[39m data_max = _array_api._nanmax(X, axis=\u001B[32m0\u001B[39m, xp=xp)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2944\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2942\u001B[39m         out = X, y\n\u001B[32m   2943\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2944\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2945\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2946\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1130\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1128\u001B[39m     n_samples = _num_samples(array)\n\u001B[32m   1129\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_samples < ensure_min_samples:\n\u001B[32m-> \u001B[39m\u001B[32m1130\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1131\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m sample(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m) while a\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1132\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1133\u001B[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001B[32m   1134\u001B[39m         )\n\u001B[32m   1136\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_features > \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m array.ndim == \u001B[32m2\u001B[39m:\n\u001B[32m   1137\u001B[39m     n_features = array.shape[\u001B[32m1\u001B[39m]\n",
      "\u001B[31mValueError\u001B[39m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 화면을 보고 실습 코드를 작성해주세요."
   ],
   "metadata": {
    "id": "hK-gAAQzS2fr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 시퀀스 데이터 생성\n",
    "def create_sequences(data, seq_length):\n",
    "  X, y = [], []\n",
    "  for i in range(len(data) - seq_length):\n",
    "      X.append(data_scaled[i:i + seq_length])\n",
    "      y.append(data_scaled[i + seq_length])\n",
    "  return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "seq_length =50\n",
    "X, y = create_sequences(data_scaled, seq_length)\n",
    "\n",
    "# 훈련/테스트 데이터 분할\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential([\n",
    "    Input(shape=(seq_length, 1)),  #추가됨\n",
    "    LSTM(units=50, return_sequences=True),\n",
    "    LSTM(units=50, return_sequences=False),\n",
    "    Dense(units=25, activation='relu'),\n",
    "    Dense(units=1)\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual, label=\"Actual Price\", color='blue')\n",
    "plt.plot(predictions, label=\"Predicted Price\", color='red')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Apple Stock Price Prediction using LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sFucihlx18aF",
    "outputId": "24a9becf-f2e8-426d-98b0-2e891f5701a9",
    "ExecuteTime": {
     "end_time": "2025-08-23T08:12:14.251344Z",
     "start_time": "2025-08-23T08:12:14.220197Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      7\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m np.array(X), np.array(y)\n\u001B[32m     10\u001B[39m seq_length =\u001B[32m50\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m X, y = create_sequences(\u001B[43mdata_scaled\u001B[49m, seq_length)\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# 훈련/테스트 데이터 분할\u001B[39;00m\n\u001B[32m     14\u001B[39m train_size = \u001B[38;5;28mint\u001B[39m(\u001B[32m0.8\u001B[39m * \u001B[38;5;28mlen\u001B[39m(X))\n",
      "\u001B[31mNameError\u001B[39m: name 'data_scaled' is not defined"
     ]
    }
   ],
   "execution_count": 11
  }
 ]
}
