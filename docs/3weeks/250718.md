# 13ì¼ì°¨ - 250718

# ðŸ“˜ Reviews ì •ë¦¬ - Feature Selection
![img.png](250718_1.png)



# Quantile Regression

## Point Prediction vs Prediction Sets/Intervals

* **Point prediction(í¬ì¸íŠ¸ ì˜ˆì¸¡)**: e.g. `50 mins` to airport (no uncertainty). 
  - ê³µí•­ê¹Œì§€ 50ë¶„ - ë¶ˆí™•ì‹¤ì„± ì—†ìŒ
* **Prediction intervals(ì˜ˆì¸¡ êµ¬ê°„)**: e.g. `50 \pm 5 mins`, gives uncertainty.
  -  $50 \pm 5$ë¶„ â€” ë¶ˆí™•ì‹¤ì„± í¬í•¨.
* **Point prediction** returns a real value or label.
  - í•œê°œì˜ ê°’ or ë ˆì´ë¸” ì˜ˆì¸¡
* **Prediction intervals/sets** return a set of labels or an interval.
  - ì˜ˆì¸¡ êµ¬ê°„/ì…‹íŠ¸ëŠ” ê°’ì˜ ë²”ìœ„ë‚˜ ì—¬ëŸ¬ ê°œì˜ ê°€ëŠ¥ì„± ìžˆëŠ” ê°’ì„ ë°˜í™˜í•¨


## OLS ì™€ Quantile Regression ë¹„êµ

![img.png](250718_2.png)

* **OLS (ìµœì†Œì œê³±ë²•)**: Estimates conditional **mean** of response variable.
  - ë°˜ì‘ ë³€ìˆ˜ì˜ ì¡°ê±´ë¶€ í‰ê· ì„ ì¶”ì •
* **Quantile Regression (ë¶„ìœ„ìˆ˜íšŒê·€)**: Estimates conditional **quantiles** (e.g., median).
  - ì¡°ê±´ë¶€ ë¶„ìœ„ìˆ˜ (ì˜ˆ: ì¤‘ì•™ê°’) ì¶”ì •

  * Provides prediction **intervals** (e.g., 5% & 95% quantiles for 90% interval).
    -  5%, 95% ë¶„ìœ„ìˆ˜ë¥¼ êµ¬í•´ 90% ì˜ˆì¸¡ êµ¬ê°„ì„ êµ¬ì„± ê°€ëŠ¥

## `QuantileRegressor` Code (sklearn)

```python
from sklearn.linear_model import QuantileRegressor

quantiles = [0.05, 0.5, 0.95]
predictions = {}
out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool)

for quantile in quantiles:
    qr = QuantileRegressor(quantile=quantile, alpha=0)
    y_pred = qr.fit(X, y_normal).predict(X)
    predictions[quantile] = y_pred

    if quantile == min(quantiles):
        out_bounds_predictions = np.logical_or(out_bounds_predictions, y_pred >= y_normal)
    elif quantile == max(quantiles):
        out_bounds_predictions = np.logical_or(out_bounds_predictions, y_pred <= y_normal)
```


## What is a Quantile?

* Divides ordered data into equal-sized groups.
* Helps understand **spread** and **distribution** beyond averages.


## Types of Quantiles

* **Quartiles**: 4 parts

  * Q1: 25th percentile
  * Q2: 50th percentile (median)
  * Q3: 75th percentile
* **Deciles**: 10 parts (10%, ..., 90%)
* **Percentiles**: 100 parts


## How to Calculate a Quantile

**Step 1: Order the data**

Example: \$n = 9\$ values â†’ {3, 6, 7, 8, 8, 10, 13, 15, 16}

**Step 2: Calculate Rank**

$\text{Rank} = p \times (n + 1)$

For \$p = 0.25\$ (1st quartile):

$\text{Rank} = 0.25 \times (9 + 1) = 2.5$

**Why \$n+1\$?** Because data divides into \$n+1\$ intervals.

**Step 3: Determine Value**

* Interpolate between 2nd and 3rd values:

$6 + 0.5 \times (7 - 6) = 6.5$

So, Q1 = 6.5


## Formal Definition

Let \$X\$: random variable, \$F(x)\$: CDF, \$Q(p)\$: quantile function

$F(x) = P(X \leq x)$

$Q(p) = F^{-1}(p) = \inf \{x \in \mathbb{R} \mid F(x) \geq p\}$


## Motivation for Quantile Regression

* More **robust** to outliers, non-Gaussian noise
* Gives **prediction intervals**, not just points
* Works with **heteroscedastic** data


## Quantile Regression vs OLS

### OLS:

$E[Y \mid X = x] = w_0 + w_1x_1 + \cdots + w_dx_d$

* Loss: **squared loss**

### Quantile Regression:

$Q_\alpha(Y \mid X = x) = w_0(\alpha) + w_1(\alpha)x_1 + \cdots + w_d(\alpha)x_d$

* Loss: **pinball loss**


## Pinball Loss

For scalar \$z\$:

$$
\ell_\alpha(z) = \begin{cases}
  (\alpha - 1)z & \text{if } z \leq 0 \\
  \alpha z & \text{if } z > 0
\end{cases}
$$


## Error Function in Quantile Regression

$$
J(w_\alpha) = \sum_{n: y_n \geq w_\alpha^\top x_n} \alpha |y_n - w_\alpha^\top x_n| +
\sum_{n: y_n < w_\alpha^\top x_n} (1 - \alpha) |y_n - w_\alpha^\top x_n|
$$

* Minimization is via **linear programming**
* For \$\alpha = 0.5\$, reduces to **LAD (Least Absolute Deviation)**


## Pinball Loss Intuition

Let \$q\$: prediction, \$y\$: true value

$$
\ell_{0.9}(q, y) = \begin{cases}
  0.9(y - q), & \text{if } y \geq q \\
  0.1(q - y), & \text{if } y < q
\end{cases}
$$

* Underprediction is penalized more when \$\alpha\$ is high
* Loss minimized when:

$P(Y \leq q) = \alpha$

---

## Example: Food Expenditure vs Income

```python
import statsmodels.api as sm
import statsmodels.formula.api as smf

mod = smf.quantreg("foodexp ~ income", data)

quantiles = np.arange(0.05, 0.96, 0.1)

models = [
    [q, *mod.fit(q=q).params.values]
    for q in quantiles
]
```

* **OLS**: overestimates for low income
* **LAD**: slightly better
* **QR**: shows varying quantile lines (fan-shape)


## Outlier Examples

* **OLS**: strongly affected by outliers
* **LAD**: more stable
* **QR**: remains stable and spreads by quantile


## Heteroscedastic Noise

* Noise increases with input \$x\$
* **Spline regression** fits average trend
* **Quantile regression** captures uncertainty via multiple quantiles


## Important Note

**QR is not automatically valid on test data. Calibration is needed.**
