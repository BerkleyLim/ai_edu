# 26일차 - 250811

# Recurrent Neural Networks (RNN)

## 1. 시퀀스 데이터 예시

시퀀스: $ x_1, x_2, \dots, x_T $

- **음성 인식:** 오디오 → 텍스트  
  _(오디오 신호의 파형이 시간에 따라 변하므로 순서 정보 중요)_
- **기계 번역:** 텍스트 → 텍스트  
  _(문장의 앞뒤 문맥이 번역 결과에 직접 영향을 미침)_
- **감성 분석:** 텍스트 → 레이블 (긍정, 부정, 중립)  
  _(“좋다”라는 단어 앞뒤에 따라 긍/부정 의미가 달라짐)_
- **음악 생성:** 이니셜 → 음악  
- **비디오 분류:** 비디오 → 레이블  
  _(연속된 프레임의 패턴을 인식해야 함)_
- **개체명 인식 (NER):** 텍스트 → 엔티티 레이블  

## 2. 시퀀스 모델링

목표: 시퀀스의 확률 계산  
$$
P(x_1, x_2, \dots, x_T)
$$

예시:

- **올바른 문장 선택:**  
$$
P(\text{I, am, going, home}) > P(\text{I, am, going, house})
$$
(“going” 뒤에는 “home”이 더 자연스러움)

- **주식 예측:**  
$$
P(100, 110, 120, 130, 140) \; ? \; \gtrless \; P(100, 110, 120, 130, 120)
$$
(마지막 값이 떨어질지 유지/상승할지 예측)

- **일반적 예측 문제:**  
$$
P(x_1, x_2, x_3, x_4, \ ?)
$$

💡 **포인트:** RNN은 순차적 확률 모델로, 현재 시점 예측은 과거 정보에 의존.

## 3. 입력-출력 형태

- **Vector to Vector:** 고정 입력 → 고정 출력  
- **Sequence to Sequence:** 가변 입력 길이 → 가변 출력 길이

## 4. 강의 목차

1. Vanilla RNN  
2. BPTT (Backpropagation Through Time)  
3. Bidirectional RNN  
4. LSTM  
5. 학습 기법: Teacher-forcing & Scheduled sampling  
6. Sequence-to-Sequence Learning (Encoder & Decoder)  

## 5. Vanilla RNN

### Feedforward Neural Net (순방향 신경망)
$$
y_t = \phi(W_{yh} h_t + b_y)  
$$
$$
h_t = \phi(W_{hx} x_t + b_h)
$$

- 입력 간 독립성 가정 (시퀀스 관계 반영 불가)  
- 입력 길이 고정 필요

- **한계**: 독립성 가정, 고정 길이 입력

### Vanilla RNN 수식

$$
y_t = \phi(V h_t + b_y)  
$$
$$
h_t = \phi(U x_t + W h_{t-1} + b_h)
$$

- **시간 종속성 학습**: $h_t$는 이전 상태 $(h_{t-1})$를 반영  
- **가변 길이 시퀀스 처리 가능**  
- **순서 정보 유지**  
- **파라미터 공유**: $(U, W, V)$는 모든 시점에서 동일

**직관**
- $(h_t)$: 현재까지 본 정보의 요약
- $(W h_{t-1})$: 이전 정보의 영향
- $(U x_t)$: 현재 입력의 영향

## 6. RNN의 입출력 구조 예시

- **One-to-Many**: 이미지 캡션 생성  
- **Many-to-One**: 감성 분석, 액티비티 인식  
- **Many-to-Many**: 개체명 인식, 기계 번역(Encoder-Decoder), NER
- **Encoder-Decoder**: 기계 번역

## 7. BPTT (Backpropagation Through Time)

### Gradient Flow 문제
- **Exploding Gradient**:  
  $(\sigma_{\max}(W) > 1)$일 때  → 기울기 무한히 커짐
- **Vanishing Gradient**:  
  $(\sigma_{\max}(W) < 1)$일 때   → 기울기 거의 0

### 해결책

**Exploding Gradient**
- **Truncated BPTT**: 일부 시점까지만 역전파
- **Gradient Clipping**: 기울기 크기 제한
- **Adaptive Optimizer**: Adam, RMSProp

**Vanishing Gradient**
- ReLU, LeakyReLU 사용
- 가중치 초기화 (Identity)
- LSTM / GRU 사용

### Gradient Clipping (By Norm)
$$
g \leftarrow \max\left(1, \frac{\delta}{\|g\|}\right) g
$$

$(\delta)$ : 미리 정한 임계값

## 8. Truncated BPTT (TBPTT)
- $( k_1 )$: 파라미터 업데이트 간격  
- $( k_2 )$: 역전파 길이  
- 긴 시퀀스 학습 시 메모리/시간 절약

## 9. Bidirectional RNN
- 순방향 + 역방향 RNN 결합
- 양방향 문맥 정보 활용
   _(예: 단어 의미 파악 시 다음 단어 정보도 반영)_


## 10. LSTM (Long Short-Term Memory)

목표: 장기 의존성 학습, Gradient 문제 완화

### LSTM 구조
- **입력 게이트** $(i_t)$  
- **출력 게이트** $(o_t)$ 
- **망각 게이트** $(f_t)$ 
- 셀 상태 $(c_t)$ 업데이트

$$
g_t = \tanh(W_g x_t + W_{gh} h_{t-1} + b_g)
$$
$$
i_t = \sigma(W_i x_t + W_{ih} h_{t-1} + b_i)
$$
$$
f_t = \sigma(W_f x_t + W_{fh} h_{t-1} + b_f)
$$
$$
o_t = \sigma(W_o x_t + W_{oh} h_{t-1} + b_o)
$$
$$
c_t = f_t \odot c_{t-1} + i_t \odot g_t
$$
$$
h_t = o_t \odot \tanh(c_t)
$$

💡 **포인트**: $(c_t)$는 가중치 곱 없이 게이트만 거치므로 gradient 소실이 완화됨.



## 11. LSTM Autoencoder
- 시퀀스를 낮은 차원의 벡터로 압축 → 재생성
- 비지도 학습에 활용 가능
- 예: 비디오 프레임 시퀀스 압축


## 12. 학습 기법

### Teacher Forcing
- 학습 시 정답 토큰 $(y_t)$ 사용
- 추론 시 모델 출력 $( \hat{y}_t )$ 사용

### Scheduled Sampling
- $(y_t)$ 사용 확률 $(\epsilon_i)$ 점진적으로 감소
- 점진적 Teacher Forcing 감소


## 13. Attention Mechanism

### 기본 아이디어
- 입력 시퀀스의 각 시점(hidden state)에 가중치 부여  
- 컨텍스트 벡터 \(c_t\):
$$
c_t = \sum_{t'=1}^{T_x} \alpha_{t,t'} h_{t'}
$$


## 14. Visual Attention (이미지 캡션)
- CNN → 이미지 Feature Map 추출 $(a_1, \dots, a_L)$
- Attention RNN이 위치별 가중치로 단어 생성


## 15. 현업 적용 팁

1. **짧은 시퀀스**: Vanilla RNN도 가능  
2. **긴 시퀀스**: LSTM/GRU 필수  
3. **실시간 처리**: TBPTT + Gradient Clipping  
4. **고정 길이 출력**: Encoder-Decoder 구조  
5. **멀티모달 입력**: CNN + RNN 결합 (예: 이미지+텍스트)

