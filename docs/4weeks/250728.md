# 21ì¼ì°¨ - 250728

# í”¼ë“œí¬ì›Œë“œ ì‹ ê²½ë§ (Feedforward Neural Networks)

## ê°œìš”

í”¼ë“œí¬ì›Œë“œ ì‹ ê²½ë§ì€ ì…ë ¥ ë°ì´í„°ë¥¼ ìˆœë°©í–¥ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ì‹ ê²½ë§ ëª¨ë¸ì´ë‹¤. ì£¼ìš” ìœ í˜•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:

* í¼ì…‰íŠ¸ë¡ (Perceptron)
* ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP, Multilayer Perceptron)

## ì£¼ìš” ìš©ì–´

* **ë…¸ë“œ(Nodes)**: ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
* **ë ˆì´ì–´(Layers)**: ì…ë ¥, ì€ë‹‰, ì¶œë ¥ ë ˆì´ì–´ë¡œ êµ¬ì„±
* **ê°€ì¤‘ì¹˜(Weights)**: ë…¸ë“œ ê°„ ì—°ê²° ê°•ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” íŒŒë¼ë¯¸í„°
* **í™œì„±í™” í•¨ìˆ˜(Activation functions)**: ì‹ ê²½ë§ì˜ ë¹„ì„ í˜•ì„±ì„ ë¶€ì—¬í•˜ëŠ” í•¨ìˆ˜ (ì˜ˆ: sigmoid, tanh, ReLU)
* **ê¹Šì´ì™€ ë„ˆë¹„(Depth & Width)**: ë ˆì´ì–´ ìˆ˜ì™€ ê° ë ˆì´ì–´ì˜ ë…¸ë“œ ìˆ˜

## ì„ í˜• ëª¨ë¸ê³¼ ì‹ ê²½ë§ ë¹„êµ

* ì„ í˜• ëª¨ë¸:
  $\hat{y}_n = \mathbf{w}^T \phi(\mathbf{x}_n)$
* FC ì‹ ê²½ë§:
  $\mathbf{h}^{(\ell+1)} = \phi\left(\mathbf{W}^{(\ell+1)}\mathbf{h}^{(\ell)}\right)$
  í™œì„±í™” í•¨ìˆ˜ê°€ ì—†ë‹¤ë©´ í•˜ë‚˜ì˜ ì„ í˜• ë³€í™˜ê³¼ ê°™ì•„ ì—¬ëŸ¬ ì¸µì„ ì‚¬ìš©í•  í•„ìš”ê°€ ì—†ìŒ

## ì£¼ìš” í™œì„±í™” í•¨ìˆ˜

* **Sigmoid**: $\phi(x) = \frac{1}{1+e^{-x}}$
* **tanh**: $\phi(x) = \tanh(x)$
* **ReLU**: $\phi(x) = \max(0, x)$
* **Leaky ReLU**: $\phi(x) = \max(0.01x, x)$

## Softmax í•¨ìˆ˜

ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì¶œë ¥ì„ í™•ë¥  í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

$$
\hat{y}_i = \frac{e^{z_i}}{\sum_j e^{z_j}}
$$

## í•™ìŠµ ëª©í‘œ

ì‹ ê²½ë§ì€ ë‹¤ìŒê³¼ ê°™ì€ ëª©ì  í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ì—¬ í•™ìŠµí•œë‹¤:

* **Square loss** (íšŒê·€):
  $J(\theta) = \frac{1}{2N} \sum_{n=1}^{N} (y[n] - \hat{y}[n])^2$
* **Cross-entropy error** (ë¶„ë¥˜):
  $J(\theta) = -\sum_{n=1}^{N}\sum_{k=1}^{K} y_k[n]\log(\hat{y}_k[n])$

ëª©ì  í•¨ìˆ˜ì˜ ìµœì†Œí™”ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜(SGD, RMSProp, ADAM ë“±)ì„ í†µí•´ ì´ë£¨ì–´ì§„ë‹¤.

---


# Perceptron Summary

## 1. Linear Classification
- ì„ í˜• ê²°ì • í•¨ìˆ˜  
  \( f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b \)
- ê²°ì • ê¸°ì¤€:  
  \( \text{sign}(f(\mathbf{x})) = \begin{cases} +1 & \text{if } f(\mathbf{x}) > 0 \\ -1 & \text{otherwise} \end{cases} \)


## 2. Perceptron ê°œë…
- Rosenblatt (1958)
- ì²« ë²ˆì§¸ ë°˜ë³µ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜
- ë‹¨ì¼ ê³„ì¸µ ì‹ ê²½ë§: \( y = \text{sign}(\mathbf{w}^T \mathbf{x} + b) \)
- ì˜¤ë¥˜ ê¸°ë°˜ ì—…ë°ì´íŠ¸:
  - ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œì¼ ë•Œë§Œ ì—…ë°ì´íŠ¸
- **ìˆ˜ë ´ì„± (Perceptron Convergence)**  
  - ì„ í˜• ë¶„ë¦¬ê°€ ê°€ëŠ¥í•  ê²½ìš° ìœ í•œí•œ ë‹¨ê³„ ë‚´ ìˆ˜ë ´ ë³´ì¥


## 3. Perceptron ì•Œê³ ë¦¬ì¦˜
- ëª©ì í•¨ìˆ˜:  
  \( J(\mathbf{w}) = -\sum_{x_i \in \mathcal{M}} y_i \mathbf{w}^T \mathbf{x}_i \)
- ì˜ëª» ë¶„ë¥˜ëœ ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸:  
  \( \mathbf{w} \leftarrow \mathbf{w} + y_i \mathbf{x}_i \)


## 4. ì•Œê³ ë¦¬ì¦˜ íë¦„
1. ìƒ˜í”Œ ì„ íƒ
2. ì˜ëª» ë¶„ë¥˜ ì—¬ë¶€ í™•ì¸
   - O: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
   - X: ê·¸ëŒ€ë¡œ ë‘ 
3. ë°˜ë³µ


## 5. Perceptron ìˆ˜ë ´ ì •ë¦¬
- ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥í•œ ë‘ í´ë˜ìŠ¤ \( C_1, C_2 \)ê°€ ìˆì„ ê²½ìš°
  - Perceptronì€ ìœ í•œí•œ ë‹¨ê³„ì—ì„œ ìˆ˜ë ´í•˜ì—¬ ê²½ê³„ ê²°ì •
- XOR ë¬¸ì œëŠ” í•´ê²° ë¶ˆê°€
  - (Minsky & Papert, 1969)


---

## Multilayer Perceptrons (MLPs)

### AND Problem
- ì…ë ¥: (0,0), (0,1), (1,0), (1,1)
- ì¶œë ¥: AND ë…¼ë¦¬ (ì˜¤ì§ (1,1)ë§Œ ì¶œë ¥ 1)
- ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥

### XOR Problem
- ì…ë ¥: (0,0), (0,1), (1,0), (1,1)
- ì¶œë ¥: XOR ë…¼ë¦¬ (ì„œë¡œ ë‹¤ë¥´ë©´ 1)
- **ì„ í˜• ë¶„ë¦¬ ë¶ˆê°€ëŠ¥**

### FF Net for XOR Problem
- XOR ë¬¸ì œëŠ” ë‹¨ì¸µ Perceptronìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ì—†ìŒ
- **MLP (ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ )** ì‚¬ìš©
- êµ¬ì¡°:
  - ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ â†’ ì¶œë ¥ì¸µ
  - ìˆ˜ì‹:
    ```
    hâ‚™ = Ï†(Wâ‚áµ€xâ‚™ + bâ‚)
    yâ‚™ = Ï†(Wâ‚‚áµ€hâ‚™ + bâ‚‚)
    ```
  - ì€ë‹‰ì¸µì„ í†µí•´ ë¹„ì„ í˜• ë¶„ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦


---

## ğŸ“‰ Backpropagation ë° Gradient Descent ìš”ì•½

### ğŸ”„ Backpropagation (ì—­ì „íŒŒ)

* **ì •ì˜**: ì¶œë ¥ì¸µì—ì„œ ë°œìƒí•œ ì˜¤ì°¨ë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ ì „íŒŒí•˜ì—¬ ê° ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°(gradient)ë¥¼ ê³„ì‚°í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
* **ê¸°ë³¸ ì›ë¦¬**:

  * ë§ˆì§€ë§‰ ë ˆì´ì–´(ì¶œë ¥ì¸µ)ì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°ëŠ” ì§ì ‘ ê³„ì‚° ê°€ëŠ¥
  * ì¤‘ê°„ ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ ê¸°ìš¸ê¸°ëŠ” ì²´ì¸ ë£°(chain rule)ì„ ì´ìš©í•´ ê³„ì‚°
  * ì¤‘ê°„ ë ˆì´ì–´ì—ëŠ” íƒ€ê²Ÿ ê°’ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©°, ì˜¤ì°¨ë§Œ ì—­ë°©í–¥ìœ¼ë¡œ ì „íŒŒ
  * Recursive ë°©ì‹ìœ¼ë¡œ ì¶œë ¥ì¸µ â†’ ì…ë ¥ì¸µ ë°©í–¥ìœ¼ë¡œ ê¸°ìš¸ê¸° ê³„ì‚°

### âš™ï¸ ì˜¤ì°¨ í•¨ìˆ˜ (Objective Function)

ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° $\theta$ë¥¼ ì°¾ê¸° ìœ„í•œ ìµœì í™” ë¬¸ì œ

1. **Square Loss (íšŒê·€ ë¬¸ì œ)**

$$
\mathcal{J}(\theta) = \frac{1}{2N} \sum_{n=1}^{N} (y_n - f(x_n; \theta))^2
$$

2. **Cross-Entropy Loss (ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ)**

$$
\mathcal{J}(\theta) = -\sum_{n=1}^{N} \left[ y_n \log f(x_n; \theta) + (1 - y_n) \log(1 - f(x_n; \theta)) \right]
$$

### ğŸ“ Gradient Descent (ê²½ì‚¬ í•˜ê°•ë²•)

* **ì •ì˜**: ê¸°ìš¸ê¸°ë¥¼ ë”°ë¼ ì˜¤ì°¨ê°€ ìµœì†Œê°€ ë˜ëŠ” íŒŒë¼ë¯¸í„° $\theta$ë¥¼ ì°¾ëŠ” ìµœì í™” ë°©ë²•
* **ì—…ë°ì´íŠ¸ ê·œì¹™**:

$$
\theta_{k+1} = \theta_k - \alpha \nabla \mathcal{J}(\theta_k)
$$

* $\alpha$: í•™ìŠµë¥ (learning rate)
* $\nabla \mathcal{J}(\theta_k)$: $\theta_k$ ì§€ì ì—ì„œì˜ ì˜¤ì°¨í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°

### ğŸ”— ì²´ì¸ ë£° (Chain Rule) ê¸°ë°˜ì˜ Backpropagation

* ë‹¤ì¸µ ì‹ ê²½ë§ì€ í•¨ìˆ˜ì˜ ì—°ì‡„(composition) í˜•íƒœë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$
f(x; W) = f_L \circ f_{L-1} \circ \dots \circ f_1 \circ f_0(x)
$$

* ì²´ì¸ ë£°ì„ í†µí•´ ë¯¸ë¶„ê°’ì„ ê³„ì‚°:

$$
\frac{\partial}{\partial x}(g \circ f)(x) = g'(f(x)) \cdot f'(x)
$$

* ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì˜ ì²´ì¸ ë£°:

$$
\frac{\partial}{\partial x}(g \circ f)(x) = \frac{\partial g}{\partial f} \frac{\partial f}{\partial x}
$$

### ğŸ–¥ï¸ ê³„ì‚° ê·¸ë˜í”„ (Computational Graph)

* ê·¸ë˜í”„ì˜ ê° ë…¸ë“œëŠ” ê¸°ë³¸ ì—°ì‚°(add, multiply, max ë“±)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
* ê° ë…¸ë“œì—ì„œì˜ gradient íë¦„ ë°©ì‹:

  * **Add**: gradientë¥¼ ê· ë“± ë¶„ë°°
  * **Multiply**: ì…ë ¥ê°’ì„ ì„œë¡œ êµì°¨í•˜ì—¬ gradient ì „íŒŒ
  * **Max**: gradientë¥¼ ìµœëŒ€ ì…ë ¥ê°’ì—ë§Œ ì „ë‹¬

ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ, ë³µì¡í•œ ì‹ ê²½ë§ì—ì„œë„ íš¨ê³¼ì ìœ¼ë¡œ gradientë¥¼ ê³„ì‚°í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


---

## ğŸ“ˆ Stochastic Gradient Descent (SGD)


### ğŸ“¦ Batch & Mini-Batch

* **Batch**: ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ì˜ë¯¸í•˜ë©° $(\mathbf{X}, \mathbf{y})$ë¡œ í‘œí˜„ë¨
* **Mini-Batch**: í•™ìŠµ ë°ì´í„°ë¥¼ ì‘ì€ ë©ì–´ë¦¬ë¡œ ë‚˜ëˆˆ ê²ƒ

  * ì˜ˆì‹œ: í¬ê¸° $M$ì¸ ë¯¸ë‹ˆë°°ì¹˜

    * $\mathbf{X}^{(m)} = \{x_m, \dots, x_{m+M-1}\}$
    * $\mathbf{y}^{(m)} = \{y_m, \dots, y_{m+M-1}\}$


### ğŸ“‰ Gradient Descent: Full-Batch

* ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì˜ ì—…ë°ì´íŠ¸ë§ˆë‹¤ ì „ì²´ gradient ê³„ì‚°
* ì—…ë°ì´íŠ¸ ê³µì‹:

$\theta_{k+1} = \theta_k - \alpha \left[ \frac{dJ(\theta; \mathbf{X}, \mathbf{y})}{d\theta} \right]_{\theta=\theta_k}$

* **ì¥ì **: ì •í™•í•œ gradient ê³„ì‚°
* **ë‹¨ì **:

  * ê³„ì‚° ë¹„ìš©ì´ í¼ (ëŠë¦¼)
  * ë°ì´í„°ê°€ ì»¤ì§€ë©´ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸° í˜ë“¬
  * ì˜¨ë¼ì¸ í•™ìŠµ ë¶ˆê°€ëŠ¥ (ìƒˆë¡œìš´ ë°ì´í„°ì— ì¦‰ì‹œ ë°˜ì˜ ë¶ˆê°€)


### ğŸ“Š Mini-Batch Gradient Descent

* ì „ì²´ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ê° ë°°ì¹˜ ë‹¨ìœ„ë¡œ gradient ê³„ì‚° ë° íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

* **ëª©ì  í•¨ìˆ˜**: ê° ë°°ì¹˜ì˜ í‰ê·  ì˜¤ì°¨

$J(\theta; \mathbf{X}, \mathbf{y}) = \frac{1}{N_M} \sum_{m=1}^{N_M} J(\theta; \mathbf{X}^{(m)}, \mathbf{y}^{(m)})$

* **ì—…ë°ì´íŠ¸ ê³µì‹**:

$\theta_{k+1} = \theta_k - \alpha \left[ \frac{dJ(\theta; \mathbf{X}^{(k)}, \mathbf{y}^{(k)})}{d\theta} \right]_{\theta=\theta_k}$

* ë˜ëŠ” ë°°ì¹˜ í¬ê¸°ê°€ 1ì¼ ê²½ìš° (Stochastic):

$\theta_{t+1} = \theta_t - \alpha \left[ \frac{dJ(\theta; x_t, y_t)}{d\theta} \right]_{\theta=\theta_t}$


### ğŸ”„ Stochastic Gradient Descent (SGD)

* **ì •ì˜**: ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°ë¥¼ 1ë¡œ ì„¤ì •í•˜ì—¬ ë§¤ìš° ë¹ ë¥´ê²Œ ë°˜ë³µ ì—…ë°ì´íŠ¸
* **íŠ¹ì§•**:

  * ë¹ ë¥´ê²Œ ìˆ˜ë ´ ê°€ëŠ¥í•˜ì§€ë§Œ ê²½ë¡œì— ì§„ë™ì´ ë°œìƒ
  * ìˆ˜ë ´ ê²½ë¡œê°€ ë¶ˆì•ˆì •í•˜ë‚˜ ìì£¼ local minimum íƒˆì¶œ ê°€ëŠ¥
  * epoch ìˆ˜ ì¦ê°€ì— ë”°ë¼ ì ì°¨ ì•ˆì •í™”ë¨

> **Figure**: SGDëŠ” ê²½ì‚¬ê°’ì˜ ì§„ë™ì´ í¬ì§€ë§Œ ë¹ ë¥¸ ìˆ˜ë ´ì„ ë³´ì„ (Wikipedia ì¶œì²˜ ì‹œê°í™” í¬í•¨)



---

## Exponentially Weighted Moving Average (EWMA)

### â–¶ï¸ ì •ì˜

* ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„° ì‹œê·¸ë‹ˆìŠ¤:
  $\theta_1, \theta_2, \theta_3, \ldots$

* ì§€ìˆ˜ì´ë™í‰ê·  (Exponentially Weighted Moving Average) ê³„ì‚°:

  $$
  v_t = \beta v_{t-1} + (1 - \beta)\theta_t
  $$


### íšŒê·€ ê´€ê³„ ë° ì˜ˆì‹œ ($v_0 = 0$ ì„¤ì •)

* $v_1 = (1 - \beta)\theta_1$
* $v_2 = (1 - \beta)(\beta \theta_1 + \theta_2)$
* $v_3 = (1 - \beta)(\beta^2 \theta_1 + \beta \theta_2 + \theta_3)$
* ì¼ë°˜í™”:

  $$
  v_t = (1 - \beta)(\beta^{t-1} \theta_1 + \beta^{t-2} \theta_2 + \cdots + \theta_t)
  $$
* **ë°˜ì˜ ê°’ ê³„ì‚°ì˜ ê°€ì¥ ìµœê·¼ $\theta$ë“¤ì— ê°€ì¥ ê°•í•œ ê°’ë§Œ ë³´ì¡°í•˜ê³  ë³´ê±´ ì‹œê°„ë„ ê°€ì¥ ê¹Œêš¸:**
  $\approx \frac{1}{1 - \beta} \text{ samples}$


### í‘œí˜„ ì‹œê°í™”

* **(a)** data
* **(b)** moving average with $\beta = 0.9$


## Bias Correction (í‰ê·  í‰ê¸°ì˜ í‰í™” ë³´ì •)

### â–¶ï¸ ë°˜í™˜ ì‚¬í•­

* ìµœì ì€ $v_0 = 0$ì—ì„œ ì‹œì‘í•´ ì´ˆê¸°ì— $v_t$ê°€ ê°€ë³ê²Œ ê³„ì‚°ë˜ë©° **í¸í–¥ (bias)** ê°€ ìƒê¸´ë‹¤.
* í•´ê²° ë°©ë²•:

$$
\hat{v}_t = \frac{v_t}{1 - \beta^t}
$$

### í‰í™” í‰ê·  ë³´ì • êµ¬í˜„

* (a) moving average only
* (b) with bias correction

---

# Gradient Descent with Momentum

> ì¶œì²˜: Ning Qian (1999), *On the momentum term in gradient descent learning algorithms*, Neural Networks.


## 1. ê¸°ë³¸ Gradient Descent ë³µìŠµ

ê¸°ë³¸ì ì¸ ê²½ì‚¬í•˜ê°•ë²•ì€ ë‹¤ìŒ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„ë©ë‹ˆë‹¤:

$\theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t)$

* $\alpha$: í•™ìŠµë¥  (step size)
* $\nabla J(\theta_t)$: í˜„ì¬ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°


## 2. Momentum ê¸°ë²• ì†Œê°œ

**Momentum**ì€ ê³¼ê±° ê¸°ìš¸ê¸°ì˜ ì§€ìˆ˜ ì´ë™ í‰ê· ì„ í™œìš©í•´ ì§„ë™ì„ ì¤„ì´ê³  ë” ë¹ ë¥¸ ìˆ˜ë ´ì„ ìœ ë„í•©ë‹ˆë‹¤.

ì—…ë°ì´íŠ¸ ìˆ˜ì‹:

$$
\begin{aligned}
  v_{t+1} &= \beta v_t + (1 - \beta) \nabla J(\theta_t) \\
  \theta_{t+1} &= \theta_t - \alpha v_{t+1}
\end{aligned}
$$

* $v_t$: ì¶•ì ëœ ê¸°ìš¸ê¸°(ì†ë„)
* $\beta$: ëª¨ë©˜í…€ ê³„ìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 0.9 ë“± ì‚¬ìš©)
* ì´ì „ ë°©í–¥ìœ¼ë¡œì˜ 'ê´€ì„±'ì„ ì£¼ì–´ ìµœì ì ì— ë” ë¹ ë¥´ê²Œ ë„ë‹¬í•˜ê²Œ í•¨


## 3. ì‹œê°ì  ë¹„êµ

| Without Momentum | With Momentum   |
| ---------------- | --------------- |
| ì§„ë™í•˜ë©° ëŠë¦° ìˆ˜ë ´       | ë¹ ë¥´ê³  ì¼ê´€ëœ ë°©í–¥ìœ¼ë¡œ ìˆ˜ë ´ |


## 4. í•µì‹¬ íš¨ê³¼

* **ì•ˆì •ì  ìˆ˜ë ´**: ë™ì¼ ë°©í–¥ì˜ ê¸°ìš¸ê¸°ê°€ ê³„ì†ë˜ë©´ ì´ë™ í¬ê¸°ë¥¼ ì¦ê°€ì‹œì¼œ ë” ë¹ ë¥´ê²Œ ìˆ˜ë ´
* **ì§„ë™ ì–µì œ**: ê¸°ìš¸ê¸° ë°©í–¥ì´ ìì£¼ ë°”ë€” ê²½ìš° ë³€í™”í­ì„ ì¤„ì—¬ í”ë“¤ë¦¼ì„ ì™„í™”


## 5. ìš”ì•½

ëª¨ë©˜í…€ ê¸°ë²•ì€ ê²½ì‚¬í•˜ê°•ë²•ì˜ ì§„ë™ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ë” ë¹ ë¥´ê³  ì•ˆì •ì ì¸ í•™ìŠµì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” ì¤‘ìš”í•œ ìµœì í™” ì „ëµì…ë‹ˆë‹¤.


---

## RMSProp

> T. Tieleman and G. Hinton (2012),
> â€œLecture 6.5 - RMSProp, COURSERA: Neural Networks for Machine Learningâ€


### ğŸ”¹ ê°œë°œ ë¶„ì„

* **RMSProp = Rprop + SGD**
* ê° weight ë§ˆë‹¤ ê°œë³„ì ì¸ (ìë™ ì¡°ì ˆ) í•™ìŠµë¥  ì ìš©
* ê³¼ê±° ëª¨ë“  ì œê³  ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë³µì‚¬ í†µê³„ê°€ ì•„ë‹ˆë¼,
  **ì´ë™ í‰ê· (moving average)** ì„ ì´ìš©í•˜ì—¬ ê·¸ë˜ë””ì–´íŠ¸ì˜ í¬ê¸°ë¥¼ ì¡°ì ˆ


### ğŸ”¹ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

1. **ì œê³  ê·¸ë˜ë””ì–´íŠ¸ ì´ë™ í‰ê· **

   $$
   r_{t+1} = \beta r_t + (1 - \beta) \left[\nabla J(\theta_t)\right]^2
   $$

   > *(element-wise square)*

2. **í‰ê·  ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ê°œê° ê·¸ë˜ë””ì–´íŠ¸ ì¡°ì ˆ**

   $$
   v_{t+1} = \frac{\nabla J(\theta_t)}{\sqrt{r_{t+1}} + \epsilon}
   $$

   > *(element-wise division)*

3. **íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸**

   $$
   \theta_{t+1} = \theta_t - \alpha v_{t+1}
   $$


---


# Optimizer & Learning Rate Summary

## ADAM Optimization

### 1. Adam Optimizer ê°œìš”

* 1ì°¨(momentum), 2ì°¨(momentum) ëª¨ë©˜íŠ¸ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµë¥ ì„ ì ì‘ì ìœ¼ë¡œ ì¡°ì •.
* ê° íŒŒë¼ë¯¸í„°ë§ˆë‹¤ ê°œë³„ì ì¸ í•™ìŠµë¥ ì„ ì‚¬ìš©í•¨.
* êµ¬ì„± ìš”ì†Œ:

  * Momentum
  * Bias correction
  * RMSProp

### 2. ì—…ë°ì´íŠ¸ ê³µì‹

```math
v_t = \beta_1 v_{t-1} + (1 - \beta_1) \nabla \mathcal{J}(\theta_{t-1})
```

```math
r_t = \beta_2 r_{t-1} + (1 - \beta_2) (\nabla \mathcal{J}(\theta_{t-1}))^2
```

```math
v_t^{bc} = \frac{v_t}{1 - \beta_1^t}, \quad r_t^{bc} = \frac{r_t}{1 - \beta_2^t}
```

```math
\theta_t = \theta_{t-1} - \alpha \cdot \frac{v_t^{bc}}{\sqrt{r_t^{bc}} + \epsilon}
```

### 3. ì‹œê°ì  ë¹„êµ (MNIST with dropout)

* Adamì€ ë‹¤ë¥¸ ì˜µí‹°ë§ˆì´ì €ë“¤ë³´ë‹¤ ë¹ ë¥¸ ìˆ˜ë ´ê³¼ ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ë³´ì„.


## SGD with \$\ell\_2\$ Regularization (Weight Decay)

### 1. ì •ì˜

```math
\widetilde{\mathcal{J}}(\theta) = \mathcal{J}(\theta) + \frac{\lambda}{2} \|\theta\|_2^2
```

### 2. ì—…ë°ì´íŠ¸ ê³µì‹

```math
\theta_t = (1 - \alpha\lambda)\theta_{t-1} - \alpha \nabla \mathcal{J}(\theta_{t-1})
```

* í•™ìŠµë¥ ì´ ì‘ê±°ë‚˜ \$\lambda\$ê°€ í´ ê²½ìš° íŒŒë¼ë¯¸í„° ì¶•ì†Œ íš¨ê³¼ê°€ í¼.


## Adam with \$\ell\_2\$ Regularization vs AdamW

### 1. Adam + Weight Decay

```math
\theta_t = \theta_{t-1} - \alpha \cdot \frac{\beta_1 v_{t-1} + (1 - \beta_1) \nabla \mathcal{J}(\theta_{t-1}) + \lambda \theta_{t-1}}{\sqrt{r_t}}
```

* ë¬¸ì œì : í° gradientì˜ ê²½ìš° rì´ ì»¤ì§€ê³ , ê·¸ì— ë”°ë¼ decayê°€ ì¶•ì†Œë¨.
* ì‘ì€ gradientì—ëŠ” decayê°€ ê°•í•˜ê²Œ ì‘ìš©í•¨. ì¦‰, íš¨ê³¼ê°€ ê³ ë¥´ì§€ ì•ŠìŒ.

### 2. AdamW

```math
\theta_t = \theta_{t-1} - \alpha \left( \frac{v_t^{bc}}{\sqrt{r_t^{bc}} + \epsilon} + \lambda \theta_{t-1} \right)
```

* Weight decayë¥¼ gradient ê³„ì‚°ê³¼ ë¶„ë¦¬(decoupled)í•˜ì—¬ ì ìš©.


## Experiments: Adam vs AdamW

* ì‹¤í—˜ ê²°ê³¼ AdamWê°€ ì¼ë°˜í™” ì„±ëŠ¥ì—ì„œ ë” ìš°ìˆ˜í•¨.
* \$\ell\_2\$ regularizationê³¼ learning rate ê°„ decouplingì´ ì˜ ì‘ë™í•¨.


## Learning Rates

### Learning Rate ì¡°ì • íš¨ê³¼

* ë„ˆë¬´ í¬ë©´ ë°œì‚°í•˜ê±°ë‚˜ ìˆ˜ë ´ì´ ì–´ë ¤ì›€.
* ë„ˆë¬´ ì‘ìœ¼ë©´ ëŠë¦° ìˆ˜ë ´.
* ì ì ˆí•œ learning rateëŠ” ì†ì‹¤ì„ ì•ˆì •ì ì´ê³  ë¹ ë¥´ê²Œ ì¤„ì—¬ì¤Œ.

### Learning Rate Decay

* í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ê°ì†Œì‹œí‚´.
* 1 epoch = ì „ì²´ ë°ì´í„°ì…‹ 1íšŒ í•™ìŠµ

#### ë°©ë²•ë“¤

1. Inverse Time Decay

```math
\alpha = \frac{1}{1 + \eta\Omega} \alpha_0
```

2. Exponential Decay

```math
\alpha = 0.95^\Omega \alpha_0
```

3. Root Decay

```math
\alpha = \frac{k}{\sqrt{\Omega}} \alpha_0
```

4. Time-based Step Decay

```math
\alpha = \frac{k}{\sqrt{t}} \alpha_0
```


## Step Decay

* í•™ìŠµë¥ ì„ ì¼ì • ê°„ê²©(epoch)ë§ˆë‹¤ ê¸‰ê²©íˆ ì¤„ì„.
* ì˜ˆ: 25 epochë§ˆë‹¤ 1/10ë¡œ ê°ì†Œ


## Cyclical Learning Rates

* ì¼ì • ë²”ìœ„ ë‚´ì—ì„œ learning rateë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì¦ê°€/ê°ì†Œì‹œí‚´.
* ë‘ ê°€ì§€ ìŠ¤ì¼€ì¤„:

  1. Triangular with fixed decay
  2. Triangular with exponential decay

---

# Dropout

## 1. Overfitting in Deep Nets

* ê¹Šì€ ì‹ ê²½ë§ì€ **ê³¼ì í•©(overfitting)** ë¬¸ì œê°€ ë°œìƒí•˜ê¸° ì‰½ë‹¤.
* ê¸°ì¡´ì˜ L1, L2 ì •ê·œí™” ë°©ì‹ì€ **co-adaptation(ê³µë™ ì ì‘)** ë¬¸ì œë¡œ ì¸í•´ ì˜ ì‘ë™í•˜ì§€ ì•ŠìŒ.
* ëª¨ë¸ ì•™ìƒë¸” ë°©ì‹ì€ ê³¼ì í•©ì„ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ, í›ˆë ¨ ë° ìœ ì§€ ë¹„ìš©ì´ í¼.

## 2. Dropoutì´ë€?

* **ê³µë™ ì ì‘(co-adaptation)** ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ ì •ê·œí™” ê¸°ë²•.
* í•˜ë‚˜ì˜ ëª¨ë¸ì´ **ë‹¤ìˆ˜ì˜ ì„œë¡œ ë‹¤ë¥¸ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì‹œë®¬ë ˆì´ì…˜**í•˜ëŠ” ë°©ì‹.
* í›ˆë ¨ ì¤‘ ë¬´ì‘ìœ„ë¡œ ë‰´ëŸ°ì„ ë„ê³ , ê° í•™ìŠµ ë°˜ë³µë§ˆë‹¤ ë‹¤ë¥¸ êµ¬ì¡°ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ìƒì„±í•˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì§.

## 3. Dropoutì˜ ì‘ë™ ë°©ì‹

* ê° ë ˆì´ì–´ì˜ ë‰´ëŸ°ì— ëŒ€í•´ **Bernoulli ë¶„í¬**ë¥¼ í†µí•´ ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¼ë¶€ ë‰´ëŸ°ë§Œ í™œì„±í™”í•¨.
* ìˆ˜ì‹ í‘œí˜„:

  * ë“œë¡­ì•„ì›ƒ ë§ˆìŠ¤í¬: $z_i^{(l)} \sim Bern(p)$
  * í”¼ë“œí¬ì›Œë“œ ì—°ì‚°: $h_i^{(l+1)} = \sigma \left( (W_i^{(l+1)} \cdot (h^{(l)} \odot z^{(l)})) + b_i^{(l+1)} \right)$

## 4. í…ŒìŠ¤íŠ¸ ì‹œ ì²˜ë¦¬ ë°©ì‹

* í•™ìŠµ ì‹œ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”ëœ ë‰´ëŸ°ë“¤ì„ ê³ ë ¤í•˜ì—¬ **í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ëª¨ë“  ë‰´ëŸ°ì„ ì‚¬ìš©**í•¨.
* ëŒ€ì‹  í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í™•ë¥  $p$ì— ë”°ë¼ **ì¶œë ¥ ê°’ì„ ì¶•ì†Œ(scale)** í•˜ì—¬ ì˜ˆì¸¡ì„ ì•ˆì •í™”ì‹œí‚´:

  * ì˜ˆ: $pw_1, pw_2, pw_3$
* ì´ëŠ” ì—¬ëŸ¬ ì–‡ì€(thinned) ë„¤íŠ¸ì›Œí¬ì˜ ì•™ìƒë¸”ì„ í‰ê· ë‚´ëŠ” íš¨ê³¼ì™€ ìœ ì‚¬.

## ìš”ì•½

* Dropoutì€ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë‰´ëŸ° ì¼ë¶€ë¥¼ ë¬´ì‘ìœ„ë¡œ ë„ëŠ” ë°©ì‹ìœ¼ë¡œ, í•˜ë‚˜ì˜ ëª¨ë¸ì´ ë‹¤ì–‘í•œ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ë„ë¡ ìœ ë„í•¨.
* í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ë˜, í™•ë¥ ì ìœ¼ë¡œ ì¡°ì •ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì„.
