# 21일차 - 250728

# 피드포워드 신경망 (Feedforward Neural Networks)

## 개요

피드포워드 신경망은 입력 데이터를 순방향으로 전달하여 출력을 생성하는 신경망 모델이다. 주요 유형은 다음과 같다:

* 퍼셉트론(Perceptron)
* 다층 퍼셉트론(MLP, Multilayer Perceptron)

## 주요 용어

* **노드(Nodes)**: 신경망의 기본 구성 요소
* **레이어(Layers)**: 입력, 은닉, 출력 레이어로 구성
* **가중치(Weights)**: 노드 간 연결 강도를 나타내는 파라미터
* **활성화 함수(Activation functions)**: 신경망의 비선형성을 부여하는 함수 (예: sigmoid, tanh, ReLU)
* **깊이와 너비(Depth & Width)**: 레이어 수와 각 레이어의 노드 수

## 선형 모델과 신경망 비교

* 선형 모델:
  $\hat{y}_n = \mathbf{w}^T \phi(\mathbf{x}_n)$
* FC 신경망:
  $\mathbf{h}^{(\ell+1)} = \phi\left(\mathbf{W}^{(\ell+1)}\mathbf{h}^{(\ell)}\right)$
  활성화 함수가 없다면 하나의 선형 변환과 같아 여러 층을 사용할 필요가 없음

## 주요 활성화 함수

* **Sigmoid**: $\phi(x) = \frac{1}{1+e^{-x}}$
* **tanh**: $\phi(x) = \tanh(x)$
* **ReLU**: $\phi(x) = \max(0, x)$
* **Leaky ReLU**: $\phi(x) = \max(0.01x, x)$

## Softmax 함수

분류 문제에서 출력을 확률 형태로 변환하는 함수

$$
\hat{y}_i = \frac{e^{z_i}}{\sum_j e^{z_j}}
$$

## 학습 목표

신경망은 다음과 같은 목적 함수를 최소화하여 학습한다:

* **Square loss** (회귀):
  $J(\theta) = \frac{1}{2N} \sum_{n=1}^{N} (y[n] - \hat{y}[n])^2$
* **Cross-entropy error** (분류):
  $J(\theta) = -\sum_{n=1}^{N}\sum_{k=1}^{K} y_k[n]\log(\hat{y}_k[n])$

목적 함수의 최소화는 최적화 알고리즘(SGD, RMSProp, ADAM 등)을 통해 이루어진다.

---


# Perceptron Summary

## 1. Linear Classification
- 선형 결정 함수  
  \( f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b \)
- 결정 기준:  
  \( \text{sign}(f(\mathbf{x})) = \begin{cases} +1 & \text{if } f(\mathbf{x}) > 0 \\ -1 & \text{otherwise} \end{cases} \)


## 2. Perceptron 개념
- Rosenblatt (1958)
- 첫 번째 반복 학습 알고리즘
- 단일 계층 신경망: \( y = \text{sign}(\mathbf{w}^T \mathbf{x} + b) \)
- 오류 기반 업데이트:
  - 잘못 분류된 샘플일 때만 업데이트
- **수렴성 (Perceptron Convergence)**  
  - 선형 분리가 가능할 경우 유한한 단계 내 수렴 보장


## 3. Perceptron 알고리즘
- 목적함수:  
  \( J(\mathbf{w}) = -\sum_{x_i \in \mathcal{M}} y_i \mathbf{w}^T \mathbf{x}_i \)
- 잘못 분류된 샘플에 대해 가중치 업데이트:  
  \( \mathbf{w} \leftarrow \mathbf{w} + y_i \mathbf{x}_i \)


## 4. 알고리즘 흐름
1. 샘플 선택
2. 잘못 분류 여부 확인
   - O: 가중치 업데이트
   - X: 그대로 둠
3. 반복


## 5. Perceptron 수렴 정리
- 선형 분리 가능한 두 클래스 \( C_1, C_2 \)가 있을 경우
  - Perceptron은 유한한 단계에서 수렴하여 경계 결정
- XOR 문제는 해결 불가
  - (Minsky & Papert, 1969)


---

## Multilayer Perceptrons (MLPs)

### AND Problem
- 입력: (0,0), (0,1), (1,0), (1,1)
- 출력: AND 논리 (오직 (1,1)만 출력 1)
- 선형 분리 가능

### XOR Problem
- 입력: (0,0), (0,1), (1,0), (1,1)
- 출력: XOR 논리 (서로 다르면 1)
- **선형 분리 불가능**

### FF Net for XOR Problem
- XOR 문제는 단층 Perceptron으로 해결할 수 없음
- **MLP (다층 퍼셉트론)** 사용
- 구조:
  - 입력층 → 은닉층 → 출력층
  - 수식:
    ```
    hₙ = φ(W₁ᵀxₙ + b₁)
    yₙ = φ(W₂ᵀhₙ + b₂)
    ```
  - 은닉층을 통해 비선형 분리를 가능하게 만듦


---

## 📉 Backpropagation 및 Gradient Descent 요약

### 🔄 Backpropagation (역전파)

* **정의**: 출력층에서 발생한 오차를 역방향으로 전파하여 각 레이어의 가중치에 대한 기울기(gradient)를 계산하는 알고리즘입니다.
* **기본 원리**:

  * 마지막 레이어(출력층)의 가중치에 대한 기울기는 직접 계산 가능
  * 중간 레이어의 가중치 기울기는 체인 룰(chain rule)을 이용해 계산
  * 중간 레이어에는 타겟 값이 존재하지 않으며, 오차만 역방향으로 전파
  * Recursive 방식으로 출력층 → 입력층 방향으로 기울기 계산

### ⚙️ 오차 함수 (Objective Function)

모델의 파라미터 $\theta$를 찾기 위한 최적화 문제

1. **Square Loss (회귀 문제)**

$$
\mathcal{J}(\theta) = \frac{1}{2N} \sum_{n=1}^{N} (y_n - f(x_n; \theta))^2
$$

2. **Cross-Entropy Loss (이진 분류 문제)**

$$
\mathcal{J}(\theta) = -\sum_{n=1}^{N} \left[ y_n \log f(x_n; \theta) + (1 - y_n) \log(1 - f(x_n; \theta)) \right]
$$

### 📐 Gradient Descent (경사 하강법)

* **정의**: 기울기를 따라 오차가 최소가 되는 파라미터 $\theta$를 찾는 최적화 방법
* **업데이트 규칙**:

$$
\theta_{k+1} = \theta_k - \alpha \nabla \mathcal{J}(\theta_k)
$$

* $\alpha$: 학습률(learning rate)
* $\nabla \mathcal{J}(\theta_k)$: $\theta_k$ 지점에서의 오차함수의 기울기

### 🔗 체인 룰 (Chain Rule) 기반의 Backpropagation

* 다층 신경망은 함수의 연쇄(composition) 형태로 볼 수 있습니다.

$$
f(x; W) = f_L \circ f_{L-1} \circ \dots \circ f_1 \circ f_0(x)
$$

* 체인 룰을 통해 미분값을 계산:

$$
\frac{\partial}{\partial x}(g \circ f)(x) = g'(f(x)) \cdot f'(x)
$$

* 다변수 함수의 체인 룰:

$$
\frac{\partial}{\partial x}(g \circ f)(x) = \frac{\partial g}{\partial f} \frac{\partial f}{\partial x}
$$

### 🖥️ 계산 그래프 (Computational Graph)

* 그래프의 각 노드는 기본 연산(add, multiply, max 등)을 나타냅니다.
* 각 노드에서의 gradient 흐름 방식:

  * **Add**: gradient를 균등 분배
  * **Multiply**: 입력값을 서로 교차하여 gradient 전파
  * **Max**: gradient를 최대 입력값에만 전달

이러한 방식으로, 복잡한 신경망에서도 효과적으로 gradient를 계산하고 파라미터를 업데이트할 수 있습니다.


---

## 📈 Stochastic Gradient Descent (SGD)


### 📦 Batch & Mini-Batch

* **Batch**: 전체 학습 데이터를 의미하며 $(\mathbf{X}, \mathbf{y})$로 표현됨
* **Mini-Batch**: 학습 데이터를 작은 덩어리로 나눈 것

  * 예시: 크기 $M$인 미니배치

    * $\mathbf{X}^{(m)} = \{x_m, \dots, x_{m+M-1}\}$
    * $\mathbf{y}^{(m)} = \{y_m, \dots, y_{m+M-1}\}$


### 📉 Gradient Descent: Full-Batch

* 전체 학습 데이터를 사용하여 한 번의 업데이트마다 전체 gradient 계산
* 업데이트 공식:

$\theta_{k+1} = \theta_k - \alpha \left[ \frac{dJ(\theta; \mathbf{X}, \mathbf{y})}{d\theta} \right]_{\theta=\theta_k}$

* **장점**: 정확한 gradient 계산
* **단점**:

  * 계산 비용이 큼 (느림)
  * 데이터가 커지면 메모리에 올리기 힘듬
  * 온라인 학습 불가능 (새로운 데이터에 즉시 반영 불가)


### 📊 Mini-Batch Gradient Descent

* 전체 데이터를 여러 미니배치로 나누어 각 배치 단위로 gradient 계산 및 파라미터 업데이트

* **목적 함수**: 각 배치의 평균 오차

$J(\theta; \mathbf{X}, \mathbf{y}) = \frac{1}{N_M} \sum_{m=1}^{N_M} J(\theta; \mathbf{X}^{(m)}, \mathbf{y}^{(m)})$

* **업데이트 공식**:

$\theta_{k+1} = \theta_k - \alpha \left[ \frac{dJ(\theta; \mathbf{X}^{(k)}, \mathbf{y}^{(k)})}{d\theta} \right]_{\theta=\theta_k}$

* 또는 배치 크기가 1일 경우 (Stochastic):

$\theta_{t+1} = \theta_t - \alpha \left[ \frac{dJ(\theta; x_t, y_t)}{d\theta} \right]_{\theta=\theta_t}$


### 🔄 Stochastic Gradient Descent (SGD)

* **정의**: 미니배치 크기를 1로 설정하여 매우 빠르게 반복 업데이트
* **특징**:

  * 빠르게 수렴 가능하지만 경로에 진동이 발생
  * 수렴 경로가 불안정하나 자주 local minimum 탈출 가능
  * epoch 수 증가에 따라 점차 안정화됨

> **Figure**: SGD는 경사값의 진동이 크지만 빠른 수렴을 보임 (Wikipedia 출처 시각화 포함)



---

## Exponentially Weighted Moving Average (EWMA)

### ▶️ 정의

* 주어진 파라미터 시그니스:
  $\theta_1, \theta_2, \theta_3, \ldots$

* 지수이동평균 (Exponentially Weighted Moving Average) 계산:

  $$
  v_t = \beta v_{t-1} + (1 - \beta)\theta_t
  $$


### 회귀 관계 및 예시 ($v_0 = 0$ 설정)

* $v_1 = (1 - \beta)\theta_1$
* $v_2 = (1 - \beta)(\beta \theta_1 + \theta_2)$
* $v_3 = (1 - \beta)(\beta^2 \theta_1 + \beta \theta_2 + \theta_3)$
* 일반화:

  $$
  v_t = (1 - \beta)(\beta^{t-1} \theta_1 + \beta^{t-2} \theta_2 + \cdots + \theta_t)
  $$
* **반영 값 계산의 가장 최근 $\theta$들에 가장 강한 값만 보조하고 보건 시간도 가장 까ꚸ:**
  $\approx \frac{1}{1 - \beta} \text{ samples}$


### 표현 시각화

* **(a)** data
* **(b)** moving average with $\beta = 0.9$


## Bias Correction (평균 평기의 평화 보정)

### ▶️ 반환 사항

* 최점은 $v_0 = 0$에서 시작해 초기에 $v_t$가 가볍게 계산되며 **편향 (bias)** 가 생긴다.
* 해결 방법:

$$
\hat{v}_t = \frac{v_t}{1 - \beta^t}
$$

### 평화 평균 보정 구현

* (a) moving average only
* (b) with bias correction

---

# Gradient Descent with Momentum

> 출처: Ning Qian (1999), *On the momentum term in gradient descent learning algorithms*, Neural Networks.


## 1. 기본 Gradient Descent 복습

기본적인 경사하강법은 다음 수식으로 표현됩니다:

$\theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t)$

* $\alpha$: 학습률 (step size)
* $\nabla J(\theta_t)$: 현재 파라미터에 대한 손실 함수의 기울기


## 2. Momentum 기법 소개

**Momentum**은 과거 기울기의 지수 이동 평균을 활용해 진동을 줄이고 더 빠른 수렴을 유도합니다.

업데이트 수식:

$$
\begin{aligned}
  v_{t+1} &= \beta v_t + (1 - \beta) \nabla J(\theta_t) \\
  \theta_{t+1} &= \theta_t - \alpha v_{t+1}
\end{aligned}
$$

* $v_t$: 축적된 기울기(속도)
* $\beta$: 모멘텀 계수 (일반적으로 0.9 등 사용)
* 이전 방향으로의 '관성'을 주어 최적점에 더 빠르게 도달하게 함


## 3. 시각적 비교

| Without Momentum | With Momentum   |
| ---------------- | --------------- |
| 진동하며 느린 수렴       | 빠르고 일관된 방향으로 수렴 |


## 4. 핵심 효과

* **안정적 수렴**: 동일 방향의 기울기가 계속되면 이동 크기를 증가시켜 더 빠르게 수렴
* **진동 억제**: 기울기 방향이 자주 바뀔 경우 변화폭을 줄여 흔들림을 완화


## 5. 요약

모멘텀 기법은 경사하강법의 진동 문제를 해결하고, 더 빠르고 안정적인 학습을 가능하게 만드는 중요한 최적화 전략입니다.


---

## RMSProp

> T. Tieleman and G. Hinton (2012),
> “Lecture 6.5 - RMSProp, COURSERA: Neural Networks for Machine Learning”


### 🔹 개발 분석

* **RMSProp = Rprop + SGD**
* 각 weight 마다 개별적인 (자동 조절) 학습률 적용
* 과거 모든 제고 그래디언트의 복사 통계가 아니라,
  **이동 평균(moving average)** 을 이용하여 그래디어트의 크기를 조절


### 🔹 파라미터 업데이트

1. **제고 그래디어트 이동 평균**

   $$
   r_{t+1} = \beta r_t + (1 - \beta) \left[\nabla J(\theta_t)\right]^2
   $$

   > *(element-wise square)*

2. **평균 값을 바탕으로 개각 그래디어트 조절**

   $$
   v_{t+1} = \frac{\nabla J(\theta_t)}{\sqrt{r_{t+1}} + \epsilon}
   $$

   > *(element-wise division)*

3. **파라미터 업데이트**

   $$
   \theta_{t+1} = \theta_t - \alpha v_{t+1}
   $$


---


# Optimizer & Learning Rate Summary

## ADAM Optimization

### 1. Adam Optimizer 개요

* 1차(momentum), 2차(momentum) 모멘트를 활용하여 학습률을 적응적으로 조정.
* 각 파라미터마다 개별적인 학습률을 사용함.
* 구성 요소:

  * Momentum
  * Bias correction
  * RMSProp

### 2. 업데이트 공식

```math
v_t = \beta_1 v_{t-1} + (1 - \beta_1) \nabla \mathcal{J}(\theta_{t-1})
```

```math
r_t = \beta_2 r_{t-1} + (1 - \beta_2) (\nabla \mathcal{J}(\theta_{t-1}))^2
```

```math
v_t^{bc} = \frac{v_t}{1 - \beta_1^t}, \quad r_t^{bc} = \frac{r_t}{1 - \beta_2^t}
```

```math
\theta_t = \theta_{t-1} - \alpha \cdot \frac{v_t^{bc}}{\sqrt{r_t^{bc}} + \epsilon}
```

### 3. 시각적 비교 (MNIST with dropout)

* Adam은 다른 옵티마이저들보다 빠른 수렴과 안정적인 결과를 보임.


## SGD with \$\ell\_2\$ Regularization (Weight Decay)

### 1. 정의

```math
\widetilde{\mathcal{J}}(\theta) = \mathcal{J}(\theta) + \frac{\lambda}{2} \|\theta\|_2^2
```

### 2. 업데이트 공식

```math
\theta_t = (1 - \alpha\lambda)\theta_{t-1} - \alpha \nabla \mathcal{J}(\theta_{t-1})
```

* 학습률이 작거나 \$\lambda\$가 클 경우 파라미터 축소 효과가 큼.


## Adam with \$\ell\_2\$ Regularization vs AdamW

### 1. Adam + Weight Decay

```math
\theta_t = \theta_{t-1} - \alpha \cdot \frac{\beta_1 v_{t-1} + (1 - \beta_1) \nabla \mathcal{J}(\theta_{t-1}) + \lambda \theta_{t-1}}{\sqrt{r_t}}
```

* 문제점: 큰 gradient의 경우 r이 커지고, 그에 따라 decay가 축소됨.
* 작은 gradient에는 decay가 강하게 작용함. 즉, 효과가 고르지 않음.

### 2. AdamW

```math
\theta_t = \theta_{t-1} - \alpha \left( \frac{v_t^{bc}}{\sqrt{r_t^{bc}} + \epsilon} + \lambda \theta_{t-1} \right)
```

* Weight decay를 gradient 계산과 분리(decoupled)하여 적용.


## Experiments: Adam vs AdamW

* 실험 결과 AdamW가 일반화 성능에서 더 우수함.
* \$\ell\_2\$ regularization과 learning rate 간 decoupling이 잘 작동함.


## Learning Rates

### Learning Rate 조정 효과

* 너무 크면 발산하거나 수렴이 어려움.
* 너무 작으면 느린 수렴.
* 적절한 learning rate는 손실을 안정적이고 빠르게 줄여줌.

### Learning Rate Decay

* 학습률을 점진적으로 감소시킴.
* 1 epoch = 전체 데이터셋 1회 학습

#### 방법들

1. Inverse Time Decay

```math
\alpha = \frac{1}{1 + \eta\Omega} \alpha_0
```

2. Exponential Decay

```math
\alpha = 0.95^\Omega \alpha_0
```

3. Root Decay

```math
\alpha = \frac{k}{\sqrt{\Omega}} \alpha_0
```

4. Time-based Step Decay

```math
\alpha = \frac{k}{\sqrt{t}} \alpha_0
```


## Step Decay

* 학습률을 일정 간격(epoch)마다 급격히 줄임.
* 예: 25 epoch마다 1/10로 감소


## Cyclical Learning Rates

* 일정 범위 내에서 learning rate를 주기적으로 증가/감소시킴.
* 두 가지 스케줄:

  1. Triangular with fixed decay
  2. Triangular with exponential decay

---

# Dropout

## 1. Overfitting in Deep Nets

* 깊은 신경망은 **과적합(overfitting)** 문제가 발생하기 쉽다.
* 기존의 L1, L2 정규화 방식은 **co-adaptation(공동 적응)** 문제로 인해 잘 작동하지 않음.
* 모델 앙상블 방식은 과적합을 줄일 수 있지만, 훈련 및 유지 비용이 큼.

## 2. Dropout이란?

* **공동 적응(co-adaptation)** 문제를 해결하기 위한 새로운 정규화 기법.
* 하나의 모델이 **다수의 서로 다른 신경망 구조를 시뮬레이션**하는 방식.
* 훈련 중 무작위로 뉴런을 끄고, 각 학습 반복마다 다른 구조의 네트워크를 생성하는 효과를 가짐.

## 3. Dropout의 작동 방식

* 각 레이어의 뉴런에 대해 **Bernoulli 분포**를 통해 무작위로 선택된 일부 뉴런만 활성화함.
* 수식 표현:

  * 드롭아웃 마스크: $z_i^{(l)} \sim Bern(p)$
  * 피드포워드 연산: $h_i^{(l+1)} = \sigma \left( (W_i^{(l+1)} \cdot (h^{(l)} \odot z^{(l)})) + b_i^{(l+1)} \right)$

## 4. 테스트 시 처리 방식

* 학습 시 무작위로 비활성화된 뉴런들을 고려하여 **테스트 시에는 모든 뉴런을 사용**함.
* 대신 학습 시 사용된 확률 $p$에 따라 **출력 값을 축소(scale)** 하여 예측을 안정화시킴:

  * 예: $pw_1, pw_2, pw_3$
* 이는 여러 얇은(thinned) 네트워크의 앙상블을 평균내는 효과와 유사.

## 요약

* Dropout은 과적합을 방지하기 위해 뉴런 일부를 무작위로 끄는 방식으로, 하나의 모델이 다양한 구조를 학습하도록 유도함.
* 테스트 시에는 전체 네트워크를 사용하되, 확률적으로 조정된 가중치를 사용하여 일반화 성능을 높임.
