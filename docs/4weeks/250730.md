# 23일차 - 250730

# Convolutional Neural Networks (CNNs) 정리

## 1. CNN 개요

* CNN은 이미지 처리에 적합한 딥러닝 모델로, 주로 필터를 이용하여 이미지의 특징을 학습하는 구조임.

## 2. 주요 CNN 아키텍처

### AlexNet (2012)

* 5개의 convolution 레이어와 3개의 fully connected 레이어로 구성.

### VGG (2015)

* 16\~19개의 깊은 convolution 레이어를 포함.

### GoogLeNet (Inception, 2015)

* 총 22개 레이어로 구성되며, inception 모듈을 사용하여 다양한 크기의 특징 추출.

### ResNet (2015)

* 18\~152개의 레이어를 가지며, skip connections (잔차 연결)을 통해 깊이 증가에도 효율적인 학습을 가능하게 함.

## 3. CNN 주요 연산

### Convolution

* 필터를 입력 데이터에 슬라이딩하여 특징을 추출하는 연산.

### Padding

* 입력 데이터의 가장자리에 값을 추가하여 출력 크기를 유지하는 기법.

### Strided Convolution

* 필터가 이동할 때 건너뛰는 간격(stride)을 조정하여 연산량 감소.

### Pooling

* 입력 데이터의 크기를 줄이며 중요한 특징만 유지 (예: Max Pooling).

## 4. 특수 CNN 구조 및 응용

### ResNet

* Skip connections 사용으로 gradient가 깊은 네트워크에서도 잘 전달됨.

### Inception 모듈

* 서로 다른 크기의 필터를 동시에 사용하여 다양한 규모의 특징 학습.

### U-Net

* 의료 영상 등에서 semantic segmentation을 위한 아키텍처.
* encoder-decoder 구조를 사용하며 skip connection으로 공간적 정보를 보존.

## 5. 주요 학습 방법과 기술

### Stochastic Gradient Descent (SGD)

* 미니 배치 데이터를 이용해 gradient를 근사적으로 계산하여 빠른 학습 수행.

### Momentum

* 과거 gradient 정보를 활용하여 gradient 방향의 관성을 유지하며 최적화 속도를 높임.

### RMSProp

* 각 파라미터에 적응적인 학습률을 적용하여 학습 안정성 증가.

### Adam

* Momentum과 RMSProp을 결합한 알고리즘으로, 빠르고 효율적인 학습 가능.

## 6. Normalization 기법

### Batch Normalization (배치 정규화)

* 미니배치 단위로 평균과 분산을 정규화하여 학습 속도 증가 및 안정화.

### Layer Normalization (레이어 정규화)

* 각 레이어의 활성화 값들을 정규화하여 재귀 신경망(RNN)에 효율적임.

## 7. Object Detection

### R-CNN 계열

* R-CNN → Fast R-CNN → Faster R-CNN으로 발전하며 region proposal 방식의 객체 검출 정확도와 속도를 개선.

### YOLO

* 입력 이미지를 하나의 CNN 연산으로 처리하여 빠른 객체 검출 수행 (실시간 가능).
* 단일 forward pass로 bounding box와 클래스 예측.

## 8. Semantic Segmentation

### Fully Convolutional Network (FCN)

* Fully convolutional 구조로 픽셀 단위 클래스 예측 수행.

### U-Net

* Skip connection을 이용하여 공간 정보를 보존하며 높은 정확도의 segmentation 제공.

## 9. Siamese Network

* 두 입력 간의 유사성을 측정하는 모델로, 이미지 verification, one-shot 학습 등에 활용됨.

## 10. CNN 응용 사례

### 시계열 분류

* 가속도계, 자이로스코프 센서를 활용하여 인간 활동 인식.
* InceptionTime과 같은 구조로 시간 정보 효율적 처리.

### 시계열 예측

* Sliding window 방식과 causal convolution을 사용하여 미래 값 예측.
* Dilated convolution을 활용하여 긴 시퀀스 의존성 학습 가능.

이 문서는 CNN의 핵심 내용을 정리하여 제공합니다.
