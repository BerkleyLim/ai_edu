# 2ì¼ì°¨ - 25ë…„ 7ì›” 2ì¼


## AI ë°œì „ì‚¬

- Aitificial Intelligence (ì¸ê³µì§€ëŠ¥)
- Machine Learning (ë¨¸ì‹ ëŸ¬ë‹)
- Deep Learning (ë”¥ëŸ¬ë‹)

> AIëŠ” ë§ì´ AIì§€ ì‹¤ì œë¡œëŠ” Machine Learning, Deep Learning??


## ë¨¸ì‹ ëŸ¬ë‹(ML) ê´€ë ¨ ìˆ˜í•™(Math)

- ì±… ì°¸ì¡° : MATHEMATICS FOR MACHINE LEARNING


## ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)

![img.png](250705_1.png)

- Learning (or training): í•™ìŠµ ë°ì´í„°ë¥¼ ì´ìš©í•œ ëª¨ë¸ í•™ìŠµ (ì§ì ‘ ë°°ìš´ë‹¤.)
- Inference (about unknowns): í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡  (ëª¨ë¥´ëŠ” ê²ƒì˜ ëŒ€í•´ ë‹µì„ ì¤€ë‹¤.)

> ì„¤ëª…: í™˜ê²½ê³¼ ë°ì´í„° ìì›ì„ ë°°ì›Œì„œ ëª¨ë¸ë¡œ ì£¼ì…ì‹œí‚¤ê³  ì´í›„ ë‹µì„ ì¤€ë‹¤.


### ë¨¸ì‹ ëŸ¬ë‹ 3ìš”ì†Œ

- Data (ë°ì´í„°)
- Models (ëª¨ë¸): í•¨ìˆ˜ë¼ê³  í‘œí˜„í•œë‹¤.
```LaTeX
Functions \( f_\theta(x) \) or probability distributions \( p_\theta(y \mid x) \)
```

![img.png](250705_2.png)

>> The model receives **Input**, processes it using a **Function** or **Probability Distribution**, and produces an **Output**.
- Algorithms: A(data) = model
\( \mathcal{A}(\text{data}) = \text{model} \)

#### ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„ íƒ ì‹œ ë°ì´í„°ì˜ ìœ í˜•ì— ë”°ë¼ ëª¨ë¸ì˜ ì¢…ë¥˜(íŒ¨ë°€ë¦¬)ë¥¼ ê²°ì •í•œë‹¤. 
- **Tabular data**: ì—‘ì…€ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì²˜ëŸ¼ í–‰ê³¼ ì—´ë¡œ ì •ë¦¬ëœ ë°ì´í„° â†’ Decision Trees, Gradient Boosting, Linear Models ë“± ì‚¬ìš©
- **Image, text, or audio data**: ë¹„ì •í˜• ë°ì´í„° â†’ CNN, RNN, Transformer, ë˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©


### Tabular Data for Regression (Tabular Data íšŒê·€)

|     | crim     | zn   | indus | chas | nox  | rm    | age   | dis    | rad | tax | ptratio | black   | lstat | medv |
|-----|----------|------|-------|------|------|-------|-------|--------|-----|-----|---------|---------|--------|------|
| 189 | 0.08370  | 45.0 | 3.44  | 0    | 0.437| 7.185 | 38.9  | 4.5667 | 5   | 398 | 15.2    | 396.90  | 5.39   | 34.9 |
| 310 | 2.63548  | 0.0  | 9.90  | 0    | 0.544| 4.973 | 37.8  | 2.5194 | 4   | 304 | 18.4    | 350.45  | 12.64  | 16.1 |
| 147 | 2.36862  | 0.0  | 19.58 | 0    | 0.871| 4.926 | 95.7  | 1.4608 | 5   | 403 | 14.7    | 391.71  | 29.53  | 14.6 |
| 471 | 4.03841  | 0.0  | 18.10 | 0    | 0.532| 6.229 | 90.7  | 3.0993 | 24  | 666 | 20.2    | 395.33  | 12.87  | 19.6 |
| 410 | 51.13580 | 0.0  | 18.10 | 0    | 0.597| 5.757 | 100.0 | 1.4130 | 24  | 666 | 20.2    | 2.60    | 10.11  | 15.0 |
| 445 | 10.67180 | 0.0  | 18.10 | 0    | 0.740| 6.459 | 94.8  | 1.9879 | 24  | 666 | 20.2    | 43.06   | 23.98  | 11.8 |
| 83  | 0.03551  | 25.0 | 4.86  | 0    | 0.426| 6.167 | 46.7  | 5.4007 | 4   | 281 | 19.0    | 390.64  | 7.51   | 22.9 |
| 457 | 8.20058  | 0.0  | 18.10 | 0    | 0.713| 5.936 | 80.3  | 2.7792 | 24  | 666 | 20.2    | 3.50    | 16.94  | 13.5 |
| 225 | 0.52693  | 0.0  | 6.20  | 0    | 0.504| 8.725 | 83.0  | 2.8944 | 8   | 307 | 17.4    | 382.00  | 4.63   | 50.0 |
| 212 | 0.21719  | 0.0  | 10.59 | 1    | 0.489| 5.807 | 53.8  | 3.6526 | 4   | 277 | 18.6    | 390.94  | 16.03  | 22.4 |



### ğŸ“Œ Machine Learning Taxonomy (ê¸°ê³„í•™ìŠµ ë¶„ë¥˜ ì²´ê³„)

ê¸°ê³„í•™ìŠµì€ í”¼ë“œë°± ë°©ì‹ê³¼ ëª©í‘œì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ ë¶„ë¥˜ëœë‹¤.

| ìœ í˜•                           | í”¼ë“œë°± ì¢…ë¥˜                   | ëª©í‘œ                                       | ì£¼ìš” í‚¤ì›Œë“œ                  |
|--------------------------------|-------------------------------|--------------------------------------------|-------------------------------|
| Supervised Learning (ì§€ë„í•™ìŠµ) | Instructive feedback (ì •ë‹µ ì œê³µ)   | Regression & Classification (ì˜ˆì¸¡, ë¶„ë¥˜)     | ê³µì—° ì„ í˜¸ ì˜ˆì¸¡ ë“±             |
| Unsupervised Learning (ë¹„ì§€ë„í•™ìŠµ) | No feedback (í”¼ë“œë°± ì—†ìŒ)       | Representation & Clustering (íŠ¹ì§•ì¶”ì¶œ, êµ°ì§‘í™”) | ì•„í‹°ìŠ¤íŠ¸ ìœ í˜• êµ°ì§‘í™” ë“±       |
| Reinforcement Learning (ê°•í™”í•™ìŠµ) | Evaluative feedback (ë³´ìƒ ê¸°ë°˜) | Sequential Decision Making (ì˜ì‚¬ê²°ì •)       | ì¶”ì²œ ìµœì í™”, í–‰ë™ ì „ëµ í•™ìŠµ ë“± |


#### ğŸ”¹ ì¶”ê°€ ê°œë…

- **Semi-supervised Learning**
  - ì¼ë¶€ë§Œ ì •ë‹µ(ë¼ë²¨) ìˆìŒ
  - ì˜ˆ: 100ê°œ ì¤‘ 10ê°œ ë¼ë²¨ â†’ ë‚˜ë¨¸ì§€ ì¶”ì •
- **Self-supervised Learning**
  - ìŠ¤ìŠ¤ë¡œ í•™ìŠµì„ ìœ„í•œ ë¬¸ì œ ìƒì„± (ë¼ë²¨ ì—†ìŒ)
  - ì˜ˆ: GPTì²˜ëŸ¼ ì¼ë¶€ ê°€ë ¤ì§„ ì…ë ¥ ì˜ˆì¸¡

#### ğŸ¯ Clnewze ì‚¬ì—… ì—°ê²° ì˜ˆì‹œ

| ì•Œê³ ë¦¬ì¦˜ ìœ í˜•        | í™œìš© ì˜ˆ |
|---------------------|---------|
| ì§€ë„í•™ìŠµ (Supervised) | ì•…ë³´ ì¥ë¥´ ë¶„ë¥˜, ê³µì—° ì¶”ì²œ, ì‚¬ìš©ì ì„ í˜¸ ì˜ˆì¸¡ |
| ë¹„ì§€ë„í•™ìŠµ (Unsupervised) | ìœ ì € ìœ í˜• êµ°ì§‘í™”, ê³µì—° í´ëŸ¬ìŠ¤í„°ë§ |
| ê°•í™”í•™ìŠµ (Reinforcement) | ì¶”ì²œ ìµœì í™”, ê´‘ê³  ë…¸ì¶œ ì „ëµ í•™ìŠµ |


#### âœ… ìš”ì•½

- ì§€ë„í•™ìŠµ: ë¼ë²¨ ìˆëŠ” ë°ì´í„° â†’ ì˜ˆì¸¡/ë¶„ë¥˜  
- ë¹„ì§€ë„í•™ìŠµ: ë¼ë²¨ ì—†ëŠ” ë°ì´í„° â†’ íŒ¨í„´/êµ°ì§‘  
- ê°•í™”í•™ìŠµ: ë³´ìƒ ê¸°ë°˜ â†’ ìµœì  í–‰ë™ ìœ ë„

â¡ï¸ Clnewze í”Œë«í¼ì—ì„œëŠ” ì§€ë„ + ë¹„ì§€ë„ í•™ìŠµì´ ì£¼ê°€ ë  ê²ƒì´ë©°,  
   ì¶”í›„ ê°•í™”í•™ìŠµì€ ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ìµœì í™”ì— ê³ ë ¤í•  ìˆ˜ ìˆìŒ.


### Resurgence of Deep Learning (ë”¥ëŸ¬ë‹ ë¶€í™œ)

- ë”¥ëŸ¬ë‹ì€ 2006ë…„ Hinton ë“±ì˜ ë…¼ë¬¸ ì´í›„ ë³¸ê²©ì ì¸ ì„±ëŠ¥ í–¥ìƒê³¼ í•¨ê»˜ ì¬ì¡°ëª…ë¨.
  > Hinton et al. (2006), "A fast learning algorithm for deep belief nets"

### Deep Neural Networks (DNNs)

#### âœ… ìˆ˜ì‹ êµ¬ì¡°

- ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ì€ ì—¬ëŸ¬ ì¸µ(Layer)ì„ ê°€ì§„ ì‹ ê²½ë§
- ìˆ˜ì‹ ì˜ˆ:
``` 
f(xâ‚™; W) = softmax(WÂ³ Ï†(WÂ² Ï†(WÂ¹ xâ‚™)))
```
- `WÂ¹`, `WÂ²`, `WÂ³`: ê° ì¸µì˜ ê°€ì¤‘ì¹˜
- `Ï†`: í™œì„±í™” í•¨ìˆ˜ (ReLU ë“±)
- `softmax`: ì¶œë ¥ì¸µì—ì„œ í™•ë¥  ê°’ìœ¼ë¡œ ë³€í™˜

#### âœ… êµ¬ì¡° ì„¤ëª…

- ì…ë ¥(Input) â†’ ì€ë‹‰ì¸µ(Dense #1, #2) â†’ ì¶œë ¥(Softmax)
- ê° ë…¸ë“œëŠ” ì• ì¸µê³¼ ì™„ì „íˆ ì—°ê²°ë¨ (Fully-connected)

#### ğŸ”¹ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ ì¢…ë¥˜

| ëª¨ë¸ | ìš©ë„ |
|------|------|
| **Fully-connected nets** | íšŒê·€, ë¶„ë¥˜ ë¬¸ì œ (ê¸°ë³¸ DNN êµ¬ì¡°) |
| **Convolutional Neural Networks (CNNs)** | ì´ë¯¸ì§€ ë¶„ì„ |
| **Recurrent Neural Networks (RNNs), LSTM** | ì‹œê³„ì—´, ìŒì„±, í…ìŠ¤íŠ¸ ë°ì´í„° |
| **Transformer** | ìì—°ì–´ ì²˜ë¦¬, ì‹œí€€ìŠ¤ ì „ì²´ ë³‘ë ¬ í•™ìŠµ |

---

#### ğŸ¯ í´ë‰´ì¦ˆ/ìŒì•… í”Œë«í¼ì—ì„œì˜ ì‘ìš© ê°€ëŠ¥ì„±

| êµ¬ì¡° | í™œìš© ì˜ˆ |
|------|---------|
| DNN / Fully-connected | ê³µì—° ì˜ˆë§¤ ìˆ˜ìš” ì˜ˆì¸¡, ì „ë¬¸ê°€ ë§¤ì¹­ |
| CNN | ì•…ë³´ ì´ë¯¸ì§€ ì¸ì‹/ë³€í™˜ |
| RNN, LSTM | ì•…ë³´ ì¬ìƒ, ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì‹œí€€ìŠ¤ ì˜ˆì¸¡ |
| Transformer | ì‚¬ìš©ì í–‰ë™ ê¸°ë°˜ ê³µì—° ì¶”ì²œ, ì±—ë´‡, ë¬¸ë§¥ ê¸°ë°˜ íƒœê·¸ ì˜ˆì¸¡ |



### Sequence to Sequence (Seq2Seq)

> ì…ë ¥ ì‹œí€¸ìŠ¤ -> ê³ ì •ëœ ë²¡í„°(ì»¨í…ìŠ¤íŠ¸) -> ì¶œë ¥ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë”¥ëŸ¬ë‹ êµ¬ì¡°

- ì˜ì–´ â†’ í”„ë‘ìŠ¤ì–´ ë²ˆì—­
- ì§ˆë¬¸ â†’ ë‹µë³€
- ìŒì„± â†’ í…ìŠ¤íŠ¸
- ì•…ë³´ â†’ ì½”ë“œ ì‹œí€€ìŠ¤
- ìœ ì € í–‰ë™ ì‹œí€€ìŠ¤ â†’ ë‹¤ìŒ ì¶”ì²œ ì‹œí€€ìŠ¤

``` 
Input: A â†’ B â†’ C â†’ <EOS>
                â†“
        [Encoder RNN êµ¬ì¡°]  
                â†“
        [Context Vector] â†’ ì´ˆê¸° hidden ìƒíƒœë¡œ ë„˜ê¹€
                â†“
        <Decoder RNN êµ¬ì¡°>
                â†“
Output: W â†’ X â†’ Y â†’ Z â†’ <EOS>
```

| ì˜ì—­  | ì„¤ëª… |
|------|---------|
| A, B, C | ì…ë ¥ ì‹œí€€ìŠ¤ (ì˜ˆ: ë¬¸ì¥, ìŒ, ë™ì‘ ë“±) End Of Sequence, ì…ë ¥ ì‹œí€€ìŠ¤ ì¢…ë£Œ ê¸°í˜¸ | 
| Encoder | ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì••ì¶•í•´ ê³ ì •ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œ ë³€í™˜ | 
| Decoder | ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶œë ¥ ì‹œí€€ìŠ¤ ìƒì„± | 
| W, X, Y, Z |ì˜ˆì¸¡ëœ ì¶œë ¥ ì‹œí€€ìŠ¤ (ì˜ˆ: ë²ˆì—­ëœ ë¬¸ì¥, ë‹µë³€ ë“±) |
| Decoder ì…ë ¥ | ì˜ˆì¸¡ëœ ì´ì „ í† í°ì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•¨ (auto-regressive) |


#### ëŒ€ê·œëª¨ ì‹œí€€ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì í•©í•œ ëª¨ë¸

- Transformer models (íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ì‹œëŒ€) 
- ì˜ˆ) chatGPT, BERT, LaMDA 


### ë”¥ëŸ¬ë‹ ë¶„ì„ ë°©ë²• (ì‚¬ì§„ìœ¼ë¡œ ì´í•´í•˜ê¸°)

#### 1ë²ˆ ê³ ì–‘ì´ì¸ê²½ìš°

![img.png](250705_3.png)

#### 2ë²ˆ ê°•ì•„ì§€ì¸ê²½ìš°

![img.png](250705_4.png)


### 3ë²ˆ í˜¸ë‘ì´ì¸ ê²½ìš°

![img.png](250705_5.png)

### 4ë²ˆ ë°”ì´ì˜¤ ë¨¸ì‹ 

![img.png](250705_6.png)


### Adversarial Attack

- ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì†ì´ê¸° ìœ„í•œ ê³µê²© ê¸°ë²•
- ì…ë ¥ì— ì•„ì£¼ ë¯¸ì„¸í•œ ì¡°ì‘ì„ ê°€í•´ AI ëª¨ë¸ì´ ì˜ëª»ëœ ì¶œë ¥ì„ ë‚´ê²Œ ìœ ë„í•˜ëŠ” ê³µê²©

![img.png](250705_7.png)


#### âš ï¸ ì™œ ìœ„í—˜í•œê°€?

| ë¶„ì•¼         | ìœ„í—˜ ì‚¬ë¡€                                      |
|--------------|-------------------------------------------------|
| ììœ¨ì£¼í–‰     | ì •ì§€ í‘œì§€íŒì— ìŠ¤í‹°ì»¤ ë¶™ì´ë©´ 'ì†ë„ ì œí•œ'ìœ¼ë¡œ ì¸ì‹ |
| ì–¼êµ´ ì¸ì‹    | ì¡°ì‘ëœ ì–¼êµ´ë¡œ ë‹¤ë¥¸ ì‚¬ëŒìœ¼ë¡œ ì¸ì‹ë¨              |
| ì½˜í…ì¸  í•„í„°ë§ | ê¸ˆì§€ ì´ë¯¸ì§€ê°€ ìš°íšŒë¨                            |
| ì¶”ì²œ ì‹œìŠ¤í…œ  | ìœ ì € ë°ì´í„° ì¡°ì‘ìœ¼ë¡œ ë¹„ì •ìƒì ì¸ ì¶”ì²œ ë°œìƒ ê°€ëŠ¥  |


#### ğŸ”§ ì£¼ìš” ê³µê²© ê¸°ë²•

| ê¸°ë²•ëª…     | ì„¤ëª… |
|------------|------|
| **FGSM** (Fast Gradient Sign Method) | ê°€ì¥ ê¸°ë³¸ì ì¸ ê³µê²©, ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë”°ë¼ í•œ ë²ˆë§Œ ì¡°ì‘ |
| **PGD** (Projected Gradient Descent) | ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•´ ë” ê°•ë ¥í•œ ê³µê²© ìˆ˜í–‰ |
| **CW Attack** | ëª¨ë¸ì„ í˜¼ë€ìŠ¤ëŸ½ê²Œ ë§Œë“œëŠ” ìµœì í™” ê¸°ë°˜ ê³µê²© |
| **Adversarial Patch** | ì‹¤ì œ ë¬¼ë¦¬ì  ìŠ¤í‹°ì»¤ë‚˜ ì´ë¯¸ì§€ë¡œ ê³µê²© (ex. ììœ¨ì£¼í–‰ ê³µê²©) |


#### ğŸ›¡ï¸ ë°©ì–´ ê¸°ë²• (Adversarial Defense)

| ë°©ë²• | ì„¤ëª… |
|------|------|
| **Adversarial Training** | ì¼ë¶€ëŸ¬ ê³µê²©ëœ ë°ì´í„°ë¥¼ í•™ìŠµì— í¬í•¨ |
| **Gradient Masking** | ê³µê²©ìš© ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ì–´ë µê²Œ í•¨ |
| **Input Preprocessing** | ë…¸ì´ì¦ˆ ì œê±°, ì••ì¶•, í•„í„°ë§ ë“± ì „ì²˜ë¦¬ ìˆ˜í–‰ |


#### ğŸ¯ Clnewze/ìŒì•… ì‚¬ì—… ì ìš© ê°€ëŠ¥ ì‹œë‚˜ë¦¬ì˜¤

| ì‘ìš© ê°€ëŠ¥ì„± | ì„¤ëª… |
|-------------|------|
| ì•…ë³´ ë¶„ì„ ê³µê²© | ì¼ë¶€ëŸ¬ ë…¸íŠ¸ê°’ì„ ì¡°ì‘í•´ ì¥ë¥´ ë¶„ë¥˜ ì˜¤ì‘ë™ ìœ ë„ |
| ì¶”ì²œ ì‹œìŠ¤í…œ ì¡°ì‘ | ìœ ì € ë¡œê·¸ë¥¼ ì¡°ì‘í•´ ì´ìƒí•œ ê³µì—°ì´ ìƒìœ„ ë…¸ì¶œë˜ê²Œ í•¨ |
| ìŠ¤íŠ¸ë¦¬ë° AI ìš°íšŒ | ìŒì›ì— ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆ ì¶”ê°€í•´ ì €ì‘ê¶Œ íƒì§€ íšŒí”¼ ê°€ëŠ¥ |


#### âœ³ï¸ ìš”ì•½

- **Adversarial Attack**ì€ AIê°€ **ì‘ì€ ì…ë ¥ ë³€í™”ì— ì·¨ì•½í•˜ë‹¤ëŠ” ì **ì„ ì´ìš©í•œ ê³µê²© ê¸°ë²•.
- **ë³´ì•ˆ, ììœ¨ì£¼í–‰, ì¶”ì²œ ì‹œìŠ¤í…œ, ìŒì•… í”Œë«í¼** ëª¨ë‘ ìœ„í—˜ì— ë…¸ì¶œë  ìˆ˜ ìˆìŒ.
- í´ë‰´ì¦ˆ ê°™ì€ ì„œë¹„ìŠ¤ë„ í–¥í›„ **ì¶”ì²œÂ·ë¶„ì„ ëª¨ë¸ì— ë°©ì–´ ê¸°ë²• ì ìš©** ê³ ë ¤í•´ì•¼ í•¨.


### Uncertainty Quantification (UQ)

- ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨

#### Point Prediction vs Prediction set/interval


| ì˜ˆì¸¡ ìœ í˜•          | ì„¤ëª… | ì˜ˆì‹œ |
|----------------|------|------|
| Regression     | í‰ê· ê°’ Âµì™€ ë¶„ì‚° var(Âµ)ì„ ê°™ì´ ì¶œë ¥ | ì˜ˆ: í‚¤ ì˜ˆì¸¡ 170 Â± 5cm |
| Classification | í´ë˜ìŠ¤ í™•ë¥  ë²¡í„° pë¡œ ì¶œë ¥í•˜ê³  ìµœëŒ€ í™•ë¥ ê°’ê³¼ entropyë¡œ ë¶ˆí™•ì‹¤ì„± íŒë‹¨ | ì˜ˆ: ê³ ì–‘ì´ 90%, ê°œ 5%, ì‚¬ì 5% â†’ Entropy ë‚®ìŒ = í™•ì‹  ìˆìŒ |

- Regression: 
Output mean y= Âµ with its variance var(Âµ)

- Classification: 
Output label y with its confidence, maxk pk , where the uncertainty of p is summarized its entropy H(p).

#### í™œìš© ë¶„ì•¼
1. ğŸ§  Semantic Segmentation
   - ë‹¨ìœ„ë¡œ ê°ì²´ë¥¼ ë¶„ë¥˜í•  ë•Œ, ëª¨í˜¸í•œ ê²½ê³„ëŠ” ë¶ˆí™•ì‹¤ì„±ì´ ë†’ìŒ
    	â†’ ì˜ˆ: ê±´ë¬¼ vs ë„ë¡œ ê²½ê³„ì—ì„œ ëª¨ë¸ì´ í—·ê°ˆë¦¬ëŠ” ê²½ìš°

2. âš ï¸ Out-of-Distribution (OOD) Detection
   - ë°ì´í„°ì™€ ë‹¤ë¥¸ ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ ê²½ê³ 
    	â†’ ì˜ˆ: ê³ ì–‘ì´/ê°œ í•™ìŠµ ëª¨ë¸ì— ê³µë£¡ ì´ë¯¸ì§€ ë“¤ì–´ì˜¤ë©´ â€œì‹ ë¢° ë¶ˆê°€â€ í‘œì‹œ

3. ğŸ¥ Healthcare Application
   -  ì˜ˆì¸¡ì— í™•ì‹  ì—†ìœ¼ë©´ ì¸ê°„ì—ê²Œ ì˜ë¢°
     	â†’ ì˜ˆ: CT ì‚¬ì§„ ë¶„ì„ ì‹œ ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ ì˜ì‚¬ì—ê²Œ ë„˜ê¹€


#### Conformal Prediction (ì í•©ì˜ˆì¸¡)

![img.png](250705_8.png)

| ì´ë¯¸ì§€                           | ì˜ˆì¸¡ ê²°ê³¼                  | í•´ì„ |
|-------------------------------|------------------------|------|
| ğŸ¿ï¸ ì™¼ìª½ squirrel               | {fox squirrel} (0.99)  | í™•ì‹  99% â†’ ëª¨ë¸ì´ ê±°ì˜ í™•ì‹  | 
| ğŸ¿ï¸ ì¤‘ê°„ squirrel               | {fox squirrel, gray, fox, bucket...} | í™•ì‹  ë–¨ì–´ì§ â†’ ì—¬ëŸ¬ ê°œ label í¬í•¨              |
| ğŸ¿ï¸ ì˜¤ë¥¸ìª½ squirrel              | {marmot, squirrel, mink, ...} | ë” ë¶ˆí™•ì‹¤ â†’ ì˜ˆì¸¡ ê²°ê³¼ê°€ ë„“ì–´ì§            |

> ğŸ“Œ ì •í™•í•œ 1ê°œ ê²°ê³¼ë§Œ ë§í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼
> ğŸ“Œ **â€œì´ ì•ˆì— ì •ë‹µì´ ìˆì„ í™•ë¥ ì´ X%ë‹¤â€**ë¼ëŠ” **ì‹ ë¢° ì§‘í•©(Set)**ì„ ì¤Œ


### Meta-Learning (Learning how to learm) - ë©”íƒ€ëŸ¬ë‹

- Model-Agnostic Meta-Learning (MAML)
- Reptile
- shot Learning (e.g., Matching Networks, Prototypical Networks)


#### Single-Task, Multi-Task, and Meta-Learning ë¹„êµ

| ì¢…ë¥˜ | ì„¤ëª… | ì˜ˆì‹œ |
|------|-------|------|
| Single-task Learning | í•˜ë‚˜ì˜ ì‘ì—…ë§Œ í•™ìŠµí•¨ | â€œì´ í™”í’ì€ ëª¨ë„¤ì¼ê¹Œ?â€œë§Œ í•™ìŠµ |
| Multi-task Learning  | ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— í•™ìŠµí•¨ | ëª¨ë„¤, ì„¸ì”, ê³ í í™”í’ì„ ë™ì‹œì— í•™ìŠµ |
| Meta-Learning | ì—¬ëŸ¬ ì‘ì—…ì˜ í•™ìŠµ ë°©ë²• ìì²´ë¥¼ í•™ìŠµ | ìƒˆ í™”í’ì„ ë´ë„ ë¹ ë¥´ê²Œ ì ì‘í•˜ë„ë¡ â€œí•™ìŠµí•˜ëŠ” ë°©ë²•â€ì„ í•™ìŠµ |

- ì˜ì‚¬ ì½”ë“œ
```python
# ì˜ì‚¬ì½”ë“œ ìˆ˜ì¤€ - Meta-Learning í•™ìŠµ êµ¬ì¡° (MAML ì˜ˆì‹œ)
for each task in tasks:
    # 1. ê° taskì—ì„œ ëª¨ë¸ ë³µì‚¬ë³¸ ìƒì„±
    model_task = clone(model)
    
    # 2. task-specific ë°ì´í„°ë¡œ inner update
    loss = loss_fn(model_task(X_train_task), y_train_task)
    loss.backward()
    model_task.update_params()  # gradient step
    
    # 3. meta update (ì›ë˜ ëª¨ë¸ì„ ê°œì„ )
    meta_loss = loss_fn(model_task(X_val_task), y_val_task)
    meta_loss.backward()

meta_optimizer.step()

```

### Meta-Learning (Learning how to learn)

> "Meta-Learning ì€ **'ì–´ë–»ê²Œ í•™ìŠµí• ì§€ í•™ìŠµí•˜ëŠ” ê²ƒ'** ì…ë‹ˆë‹¤."


#### Why Meta-Learning? (ì™œ ë©”íƒ€ ëŸ¬ë‹ì¼ê¹Œ?)
- Deep Learningì€ data-hungry (ë°ì´í„°ë¥¼ ë§¤ìš° ë§ì´ ìš”êµ¬í•¨)
- Meta-Learningì€ ê¸°ì¡´ ê²½í—˜ì„ ì¬ì‚¬ìš©í•˜ì—¬ ì ì€ ë°ì´í„°ë¡œë„ ë¹ ë¥´ê²Œ ì ì‘í•¨
- ëª©í‘œ: Few-Shot Learning ë° AutoML (ìë™í™”ëœ ë¨¸ì‹ ëŸ¬ë‹)


[//]: # (#### ì˜ˆì‹œ: ìŠ¤íƒ€ì¼ ë¶„ë¥˜ ë¬¸ì œ)

[//]: # ()
[//]: # (###### Task: â€œQuery ì´ë¯¸ì§€ëŠ” Monetì¸ê°€, Cezanneì¸ê°€?â€)

[//]: # ()
[//]: # (```html)

[//]: # (<div align="center">)

[//]: # (  <img src="attachment:file-7dKDHE2zya2SyoyvH1evjX" width="750"/>)

[//]: # (</div>)

[//]: # (```)

[//]: # (```html)

[//]: # (<div align="center">)

[//]: # (  <img src="attachment:file-EoEMBeMyreZEByyUgHDkiD" width="750"/>)

[//]: # (</div>)

[//]: # (```)

[//]: # ()
[//]: # (```html )

[//]: # (<div align="center">)

[//]: # (  <img src="attachment:file-GHb2V8T77s4YWzrVkce7qv" width="300"/>)

[//]: # (</div>)

[//]: # (```)



### Linear Probing
- ëª¨ë“  ë ˆì´ì–´ í•™ìŠµì´ ì•„ë‹Œ ë‚´ê°€ ìê¸°ê³  ìˆëŠ” ë ˆì´ì–´ë¥¼ ë§ˆì§€ë§‰ í•™ìŠµí•œê±¸ í™œìš©í•œë‹¤.
- ì˜ˆì‹œ: ChatGPTë„ ë³´ë©´ ê°€ì¥ ìµœê·¼ì— ëŒ€í™” ë‚´ìš©ì„ í™œìš©í•˜ì—¬ ë‹µë³€ ê°€ëŠ¥



---------
## [ë¦¬ë·° - 2025ë…„ 7ì›” 4ì¼ (ì„ í˜•ëŒ€ìˆ˜)]

### Vector & Norm

```python 
import numpy as np
import matplotlib.pyplot as plt

# ë²¡í„° ì •ì˜
v = np.array([3, 4])

# L2 Norm (ìœ í´ë¦¬ë””ì•ˆ ë…¸ë¦„)
l2_norm = np.linalg.norm(v)

# L1 Norm (ë§¨í•´íŠ¼ ë…¸ë¦„)
l1_norm = np.sum(np.abs(v))

# Lâˆ Norm (ìµœëŒ“ê°’ ë…¸ë¦„)
linf_norm = np.max(np.abs(v))

# ê²°ê³¼ ì¶œë ¥
print(f"L2 Norm: {l2_norm}")
print(f"L1 Norm: {l1_norm}")
print(f"Lâˆ Norm: {linf_norm}")

# ì‹œê°í™”
origin = [0], [0]
plt.quiver(*origin, v[0], v[1], angles='xy', scale_units='xy', scale=1, color='r')
plt.text(v[0], v[1], f"|v|={l2_norm:.2f}", fontsize=12)

plt.xlim(0, 5)
plt.ylim(0, 5)
plt.grid()
plt.gca().set_aspect('equal', adjustable='box')
plt.title("Vector and L2 Norm")
plt.xlabel("X")
plt.ylabel("Y")
plt.show()
```

![img.png](250705_9.png)
ğŸ§  í™”ì´íŠ¸ë³´ë“œ ë‚´ìš© ìš”ì•½ ë° í•´ì„

1. ğŸ”º ë²¡í„°ì˜ ê°œë…
	â€¢	Vectorë¼ê³  ì íŒ ì™¼ìª½ ë¶€ë¶„ì—ëŠ” ê²©ì(grid) ìœ„ì— í™”ì‚´í‘œê°€ ê·¸ë ¤ì ¸ ìˆê³ , x ë²¡í„°ê°€ ì‹œê°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
	â€¢	ì´ ë²¡í„°ëŠ” (1, 2)ë¡œ ë³´ì´ë©°, xì¶•ìœ¼ë¡œ 1, yì¶•ìœ¼ë¡œ 2ë§Œí¼ ê°„ ìœ„ì¹˜ë¥¼ ê°€ë¦¬í‚µë‹ˆë‹¤.
	â€¢	í™”ì‚´í‘œë¡œ ê·¸ë ¤ì§„ ë²¡í„°ëŠ” ë°©í–¥ê³¼ í¬ê¸°ë¥¼ ëª¨ë‘ ê°€ì§€ëŠ” 2ì°¨ì› ë²¡í„°ì…ë‹ˆë‹¤.

2. ğŸ“ Norm ì„¤ëª…
	â€¢	ì˜¤ë¥¸ìª½ì—ëŠ” â€œEuclidean Normâ€ì´ë¼ ì“°ì—¬ ìˆê³ , ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

\|x\|_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_d^2}

ì¦‰, L2 ë…¸ë¦„ìœ¼ë¡œ, ë²¡í„°ì˜ í¬ê¸°(ê¸¸ì´)ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.

3. ğŸ“Š ë²¡í„° í‘œí˜„ì‹

x = \begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_d
\end{bmatrix}
	â€¢	ì´ëŠ” dì°¨ì› ë²¡í„°ë¥¼ í–‰ë ¬ í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒì…ë‹ˆë‹¤.
	â€¢	ì˜ˆ: x = [1, 2]ë¼ë©´

\|x\|_2 = \sqrt{1^2 + 2^2} = \sqrt{5}

â¸»

#### ğŸ”§ Python ì˜ˆì œ (í•´ë‹¹ ê°•ì˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì½”ë“œë¡œ êµ¬í˜„)

```python
import numpy as np
import matplotlib.pyplot as plt

# ë²¡í„° ì •ì˜
x = np.array([1, 2])

# L2 Norm (Euclidean norm)
l2_norm = np.linalg.norm(x)

# ì‹œê°í™”
origin = [0], [0]
plt.quiver(*origin, x[0], x[1], angles='xy', scale_units='xy', scale=1, color='blue', label='Vector x')

# ë²¡í„°ì˜ ëì— ë¼ë²¨ ì¶”ê°€
plt.text(x[0], x[1], f"|x|={l2_norm:.2f}", fontsize=12, color='black', ha='left')

plt.xlim(-1, 3)
plt.ylim(-1, 3)
plt.gca().set_aspect('equal', adjustable='box')
plt.grid(True)
plt.title("Vector x and Euclidean Norm")
plt.xlabel("x1")
plt.ylabel("x2")
plt.legend()
plt.show()


```

ğŸ“Œ í•µì‹¬ ê°œë… ìš”ì•½:

| ê°œë…	| ì„¤ëª… |
|-------|------|
| ë²¡í„°	| ë°©í–¥ê³¼ í¬ê¸°ë¥¼ ê°€ì§„ ìˆ˜í•™ì  ê°ì²´ |
| L2 Norm	| ë²¡í„°ì˜ ê¸¸ì´ ê³„ì‚° ë°©ì‹: í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ ê¸°ë°˜ |
| ìš©ë„	| ê±°ë¦¬ ê³„ì‚°, ìœ ì‚¬ë„ ì¸¡ì •, ì •ê·œí™” ë“± |

![img.png](250705_10.png)



